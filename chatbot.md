Crear un chatbot puede transformar la atenci√≥n al cliente, automatizar tareas y mejorar la experiencia digital. Aqu√≠ tienes algunas de las mejores herramientas para crear chatbots, tanto con inteligencia artificial como sin necesidad de programar:

# Herramientas destacadas para crear chatbots

## 1. Tidio
Ideal para peque√±as y medianas empresas.

Editor visual muy intuitivo.

Integraci√≥n con chat en vivo y automatizaci√≥n de respuestas.

Perfecto para atenci√≥n al cliente y generaci√≥n de leads. üîó Gu√≠a de plataformas para crear chatbots ‚Äì Tidio

## 2. Landbot.io

No requiere programaci√≥n.

Se integra f√°cilmente con WhatsApp, Slack, Facebook Messenger, Google Sheets, etc.

Ideal para marketing, ventas y soporte.

Ofrece plantillas predise√±adas y estad√≠sticas de conversaci√≥n. üîó Lista de creadores de chatbot ‚Äì Geekflare

## 3. HubSpot Chatbot Builder

**Gratuito y sin l√≠mite de tiempo.**

Integrado con el CRM de HubSpot.

Automatiza tareas como agendar reuniones, calificar leads y responder consultas.

Muy √∫til para empresas que ya usan HubSpot. üîó Chatbot de IA ‚Äì HubSpot

## 4. ManyChat

Especializado en chatbots para redes sociales (Facebook Messenger, Instagram, WhatsApp).

Muy √∫til para e-commerce y campa√±as de marketing.

Ofrece automatizaci√≥n de mensajes y segmentaci√≥n de audiencia. üîó Incluido en la gu√≠a de Tidio

## 5. Chatfuel

Enfocado en redes sociales y atenci√≥n al cliente.

Permite crear bots sin c√≥digo.

Ideal para empresas que buscan automatizar respuestas en Facebook o Telegram. üîó Tambi√©n en la lista de Tidio

¬øQuieres que te recomiende una herramienta espec√≠fica seg√∫n el tipo de negocio o canal que tienes en mente (web, WhatsApp, redes sociales)? Tambi√©n puedo ayudarte a dise√±ar el flujo de conversaci√≥n inicial.

# HubSpot Chatbot Builder 
Ofrece una versi√≥n gratuita que permite a cualquier empresa crear chatbots sin necesidad de conocimientos t√©cnicos ni tarjeta de cr√©dito.

¬øQu√© puedes hacer con la versi√≥n gratuita?

Crear chatbots personalizados con plantillas y editor visual.

Automatizar tareas como agendar reuniones, calificar leads y responder preguntas frecuentes.

Integrar el chatbot con el CRM de HubSpot, para ofrecer respuestas personalizadas basadas en datos reales.

Atender clientes 24/7 en tu sitio web, y derivar a agentes humanos cuando sea necesario.

Configurar el chatbot en espa√±ol y adaptarlo a tu marca y estilo de comunicaci√≥n.

Enlaces para ampliar informaci√≥n

[P√°gina oficial de HubSpot Chatbot Builder](https://www.hubspot.es/products/crm/chatbot-builder)

[Tutorial para crear un chatbot en espa√±ol con HubSpot](https://www.inboundcycle.com/blog-de-inbound-marketing/como-crear-chatbot-espanol-hubspot)

¬øQuieres que te ayude a dise√±ar el flujo de conversaci√≥n inicial para tu chatbot o elegir la plantilla m√°s adecuada seg√∫n tu sector? Estoy listo para ayudarte a ponerlo en marcha.

# Ejemplo de flujo de conversaci√≥n para el chatbot de Medias Asensio

## Objetivo del chatbot:
	Atender consultas b√°sicas de clientes.

	Guiar al usuario en la compra online.

	Resolver dudas frecuentes sobre productos, env√≠os y tiendas f√≠sicas.

	Derivar a un agente humano si es necesario.

## Flujo de conversaci√≥n inicial

## Inicio

```plaintext
¬°Hola! üëã Bienvenido a Medias Asensio. ¬øEn qu√© podemos ayudarte hoy?
```

Opciones principales (botones o respuestas r√°pidas)
	Ver cat√°logo de productos

	Consultar estado de mi pedido

	Informaci√≥n sobre tiendas f√≠sicas

	Hablar con un agente

## Si el usuario elige ‚ÄúVer cat√°logo de productos‚Äù

```plaintext
Perfecto. ¬øQu√© tipo de producto est√°s buscando?
```
	Medias de mujer

	Calcetines de hombre

	Packs promocionales

	Ver todo el cat√°logo

Aqu√≠ puedes enlazar directamente a secciones de la tienda online.

## Si el usuario elige ‚ÄúConsultar estado de mi pedido‚Äù

```plaintext
Por favor, introduce tu n√∫mero de pedido para comprobar el estado.
```
El chatbot puede conectarse al sistema de pedidos si est√° integrado con el CRM.

## Si el usuario elige ‚ÄúInformaci√≥n sobre tiendas f√≠sicas‚Äù

```plaintext
Tenemos tiendas en Telde (Gran Canaria), Santa Cruz y Arona (Tenerife). ¬øQuieres ver horarios, direcci√≥n o c√≥mo llegar?
```

Ver horarios

Ver ubicaci√≥n

Contactar con la tienda

## Si el usuario elige ‚ÄúHablar con un agente‚Äù

```plaintext
Un momento, te conectamos con uno de nuestros compa√±eros. ‚è≥
```

Aqu√≠ se activa el chat en vivo o se deriva a un formulario de contacto si no hay agentes disponibles.

## Consejos para configurar el chatbot en HubSpot

	Usa plantillas predise√±adas para atenci√≥n al cliente.

	Activa el modo multiling√ºe si tienes clientes internacionales.

	Integra el chatbot con el CRM de HubSpot para personalizar respuestas.

	Configura mensajes de bienvenida y respuestas autom√°ticas para fuera de horario.


¬øQuieres que te ayude a redactar mensajes espec√≠ficos para promociones, devoluciones o atenci√≥n postventa? Tambi√©n puedo ayudarte a definir el tono de voz del chatbot seg√∫n la identidad de marca.



# ChatBot

¬°Buena pregunta! Crear un chatbot con Python es totalmente posible y muy flexible. Puedes hacerlo desde algo b√°sico hasta sistemas avanzados con inteligencia artificial. Aqu√≠ te muestro c√≥mo empezar paso a paso:

## 1. Chatbot b√°sico con ChatterBot
ChatterBot es una librer√≠a ideal para principiantes. Permite entrenar un bot con ejemplos de conversaci√≥n sin necesidad de programar reglas complejas.

## Ejemplo simple:

```python
from chatterbot import ChatBot
from chatterbot.trainers import ListTrainer

# Crear el chatbot
bot = ChatBot('Asistente')

# Entrenamiento con frases b√°sicas
trainer = ListTrainer(bot)
conversacion = [
    'Hola',
    'Hola, ¬øc√≥mo puedo ayudarte?',
    '¬øCu√°l es tu nombre?',
    'Me llamo Asistente, encantado de conocerte.'
]
trainer.train(conversacion)

# Probar el chatbot
print(bot.get_response('Hola'))
```
Puedes ampliar el entrenamiento con m√°s frases o conectarlo a una interfaz web.

## 2. Chatbot avanzado con Rasa
Rasa es una plataforma profesional en Python para crear chatbots con procesamiento de lenguaje natural (NLP), gesti√≥n de contexto y despliegue en producci√≥n.

Permite crear flujos de conversaci√≥n complejos.

Se integra con canales como WhatsApp, Telegram o web.

Requiere conocimientos m√°s avanzados, pero es muy potente.

## 3. Procesamiento de texto con SpaCy o NLTK
Si quieres que tu bot entienda mejor el lenguaje humano, puedes usar librer√≠as como:

SpaCy: para reconocimiento de entidades, an√°lisis sint√°ctico, etc.

NLTK: para tokenizaci√≥n, clasificaci√≥n de texto y respuestas autom√°ticas.

## Recursos √∫tiles para aprender

[Gu√≠a paso a paso para crear un chatbot en Python ‚Äì KeepCoding](https://keepcoding.io/blog/como-crear-un-chatbot-en-python/)

[Tutorial de ChatterBot en espa√±ol ‚Äì DataCamp](https://www.datacamp.com/es/tutorial/building-a-chatbot-using-chatterbot)

[Ejemplo con NLTK ‚Äì C√≥digoFuente.org](https://www.codigofuente.org/crear-chatbot-basico-python/)

¬øQuieres que te ayude a dise√±ar un flujo de conversaci√≥n espec√≠fico para tu chatbot en Python o elegir la mejor librer√≠a seg√∫n tu nivel? Estoy listo para ayudarte a construirlo paso a paso.

# Installing NLTK Data
After installing the NLTK package, please do install the necessary datasets/models for specific functions to work.

If you‚Äôre unsure of which datasets/models you‚Äôll need, you can install the ‚Äúpopular‚Äù subset of NLTK data, on the command line type `python -m nltk.downloader popular`, or in the Python interpreter `import nltk; nltk.download('popular')`

[For details, see](https://www.nltk.org/data.html)

# NLTK: Una breve introducci√≥n
NLTK (Natural Language Toolkit) es una plataforma l√≠der para crear programas Python para trabajar con datos en lenguaje humano. Proporciona interfaces f√°ciles de usar para m√°s de 50 recursos corporales y l√©xicos , como WordNet, junto con un conjunto de bibliotecas de procesamiento de texto para clasificaci√≥n, tokenizaci√≥n, derivaci√≥n, etiquetado, an√°lisis y razonamiento sem√°ntico, envoltorios para bibliotecas de PNL de potencia industrial.

NLTK ha sido llamada ‚Äúuna herramienta maravillosa para la ense√±anza y el trabajo en ling√º√≠stica computacional con Python‚Äù y ‚Äúuna biblioteca incre√≠ble para jugar con lenguaje natural‚Äù.

El procesamiento del lenguaje natural con Python proporciona una introducci√≥n pr√°ctica a la programaci√≥n para el procesamiento del lenguaje. Recomiendo este libro a las personas que comienzan en PNL con Python.

## Descargando e instalando NLTK

**Instalar NLTK:** ejecutar `pip install nltk`
**Instalaci√≥n de prueba:** ejecutar python y luego escribir `import nltk`
Para obtener instrucciones espec√≠ficas de la plataforma, pues acudir a este enlace [aqu√≠](#Installing-NLTK-Data) .

## Instalaci√≥n de paquetes NLTK
Importar NLTK y ejecutar `nltk.download()`.Esto abrir√° el descargador de NLTK desde donde puedes elegir los corpus y modelos para descargar. Tambi√©n puedes descargar todos los paquetes a la vez.

## Preprocesamiento de texto con NLTK

El problema principal con los datos de texto es que todo est√° en formato de texto (cadenas). Sin embargo, los algoritmos de aprendizaje autom√°tico necesitan alg√∫n tipo de vector de caracter√≠sticas num√©ricas para realizar la tarea. Entonces, antes de comenzar con cualquier proyecto de PNL, debemos preprocesarlo para que sea ideal para trabajar. El preprocesamiento de texto b√°sico incluye:

Convertir todo el texto en may√∫sculas o min√∫sculas , para que el algoritmo no trate las mismas palabras en diferentes casos como diferentes.

**Tokenizaci√≥n :** Tokenizaci√≥n es solo el t√©rmino usado para describir el proceso de conversi√≥n de las cadenas de texto normales en una lista de tokens, es decir, las palabras que realmente queremos. El tokenizador de oraciones se puede usar para encontrar la lista de oraciones y el tokenizador de palabras se puede usar para encontrar la lista de palabras en cadenas.
El paquete de datos NLTK incluye un **tokenizer Punkt** previamente entrenado para el ingl√©s.

Eliminar ruido, es decir, todo lo que no est√© en un n√∫mero o letra est√°ndar.

**Eliminando las Stop words.** A veces, algunas palabras extremadamente comunes que parecen tener poco valor para ayudar a seleccionar documentos que coinciden con las necesidades de un usuario se excluyen por completo del vocabulario. Estas palabras se llaman **Stop words**.

**Generaci√≥n de derivaciones:** derivaci√≥n es el proceso de reducir las palabras con inflexi√≥n (o algunas veces derivadas) a su forma de ra√≠z, base o ra√≠z, generalmente una forma de palabra escrita. Ejemplo si tuvi√©ramos que detener las siguientes palabras: ‚ÄúPan‚Äù ‚Äúpanadero, ‚Äúy panaderia‚Äù, el resultado ser√≠a una sola palabra ‚Äúpan‚Äù.

**Lemmatizaci√≥n:** una ligera variante de la derivaci√≥n es la lematizaci√≥n. La principal diferencia entre estos es que, la derivaci√≥n a menudo puede crear palabras inexistentes, mientras que los lemas son palabras reales. Por lo tanto, su ra√≠z, es decir, la palabra con la que termina, no es algo que pueda buscar en un diccionario, pero s√≠ puede buscar un lema. Algunos ejemplos de Lemmatizaci√≥n son que ‚Äúcorrer‚Äù es una forma b√°sica de palabras como ‚Äúccorriendo‚Äù o ‚Äúcorri√≥‚Äù o que la palabra ‚Äúmejor‚Äù y ‚Äúbueno‚Äù est√°n en el mismo lema, por lo que se consideran iguales.

# Bag of Words
Despu√©s de la fase de preprocesamiento inicial, necesitamos transformar el texto en un vector significativo (o matriz) de n√∫meros. La bolsa de palabras es una representaci√≥n de texto que describe la aparici√≥n de palabras dentro de un documento. Se trata de dos cosas:

	Un vocabulario de palabras conocidas.
	Una medida de la presencia de palabras conocidas.

¬øPor qu√© se llama una ‚Äúbag‚Äù of words? Esto se debe a que cualquier informaci√≥n sobre el orden o la estructura de las palabras en el documento se descarta y al modelo solo le preocupa si las palabras conocidas aparecen en el documento, no donde aparecen en el documento.

La intuici√≥n detr√°s de esta Bolsa de palabras es que los documentos son similares si tienen un contenido similar. Adem√°s, podemos aprender algo sobre el significado del documento solo a partir de su contenido.

Por ejemplo, si nuestro diccionario contiene las palabras {Learning, is, the, not, great}, y queremos vectorizar el texto ‚ÄúLearning is great‚Äù, tendr√≠amos el siguiente vector: (1, 1, 0, 0, 1).

## Enfoque TF-IDF

Un problema con el enfoque de la Bolsa de Palabras es que las palabras muy frecuentes comienzan a dominar en el documento (por ejemplo, mayor puntuaci√≥n), pero es posible que no contengan tanto ‚Äúcontenido informativo‚Äù. Adem√°s, dar√° m√°s peso a los documentos m√°s largos que a los m√°s cortos.

Un enfoque es volver a escalar la frecuencia de las palabras seg√∫n la frecuencia con la que aparecen en todos los documentos, de manera que se penalicen las puntuaciones de las palabras frecuentes como ‚Äúthe‚Äù que tambi√©n son frecuentes en todos los documentos. Este enfoque de puntuaci√≥n se denomina **Frecuencia de documentos de frecuencia inversa a t√©rmino** , o **TF-IDF** para abreviar, donde:

**Frecuencia de t√©rmino :** es una puntuaci√≥n de la frecuencia de la palabra en el documento actual.
```bash
TF = (Number of times term t appears in a document)/(Number of terms in the document)
```
**Frecuencia de documentos inversa :** es una puntuaci√≥n de cu√°n rara es la palabra entre los documentos.
```bash
IDF = 1+log(N/n), where, N is the number of documents and n is the number of documents a term t has appeared in.
```

El peso de **Tf-idf** es un peso que se usa a menudo en la recuperaci√≥n de informaci√≥n y la miner√≠a de texto. Este peso es una medida estad√≠stica que se utiliza para evaluar la importancia de una palabra para un documento de una colecci√≥n o un corpus.

Ejemplo:

Considera un documento que contiene 100 palabras en donde la palabra ‚Äútel√©fono‚Äù aparece 5 veces.

El t√©rmino **frecuencia** (es decir, tf) para tel√©fono es entonces (5/100) = 0.05. Ahora, supongamos que tenemos 10 millones de documentos y la palabra tel√©fono aparece en mil de estos. Luego, la frecuencia del documento inverso (es decir, IDF) se calcula como log (10,000,000 / 1,000) = 4. Por lo tanto, el peso de **Tf-IDF** es el producto de estas cantidades: 0.05 * 4 = 0.20.

**Tf-IDF** puede implementarse en **scikit learn** como:

desde `sklearn.feature_extraction.text import TfidfVectorizer`

## Similitud coseno

**TF-IDF** es una transformaci√≥n aplicada a los textos para obtener dos vectores de valor real en el espacio vectorial. Luego podemos obtener la similitud de coseno de cualquier par de vectores tomando su producto puntual y dividi√©ndolo por el producto de sus normas. Eso produce el coseno del √°ngulo entre los vectores. La similitud de coseno es una medida de similitud entre dos vectores distintos de cero. Usando esta f√≥rmula podemos descubrir la similitud entre dos documentos d1 y d2.
```bash
Cosine Similarity (d1, d2) = Dot product(d1, d2) / ||d1|| * ||d2||
```
Donde d1, d2 son dos vectores que no son cero.

Para una explicaci√≥n detallada y un ejemplo pr√°ctico de TF-IDF y Cosine Similarity, consulta el documento a continuaci√≥n.

## Tf-Idf and Cosine similarity
In the year 1998 Google handled 9800 average search queries every day. In 2012 this number shot up to 5.13 billion‚Ä¶
janav.wordpress.com

**Ahora tenemos una idea clara del proceso de la PNL. Es hora de que lleguemos a nuestra tarea real, es decir, la creaci√≥n de nuestro chatbot.** Llamaremos a nuestro **chatbot ‚ÄòROBOü§ñ‚Äô**.

Importando las librer√≠as necesarias.
```bash
import nltk  import numpy as np  import random  import string # to process standard python strings
```

# Cuerpo

Para nuestro ejemplo, usaremos la p√°gina de [Wikipedia para chatbots](https://en.wikipedia.org/wiki/Chatbot) como nuestro corpus. Copia el contenido de la p√°gina y col√≥calo en un archivo de texto llamado ‚Äòchatbot.txt‚Äô. Si lo prefieres, puedes utilizar otro corpus.

## Leyendo en los datos

Leeremos en el archivo **corpus.txt** y convertiremos el corpus completo en una lista de oraciones y una lista de palabras para un procesamiento previo adicional.
```bash
f=open('chatbot.txt','r',errors = 'ignore')raw=f.read()raw=raw.lower()# converts to lowercasenltk.download('punkt') # first-time use only  nltk.download('wordnet') # first-time use onlysent_tokens = nltk.sent_tokenize(raw)# converts to list of sentences   word_tokens = nltk.word_tokenize(raw)# converts to list of words
```
Veamos un ejemplo de sent_tokens y word_tokens

```bash
sent_tokens[:2]  ['a chatbot (also known as a talkbot, chatterbot, bot, im bot, interactive agent, or artificial conversational entity) is a computer program or an artificial intelligence which   conducts a conversation via auditory or textual methods.',   'such programs are often designed to convincingly simulate how a human would behave as a conversational partner, thereby passing the turing test.']  word_tokens[:2]  ['a', 'chatbot', '(', 'also', 'known']
```
**Pre-procesamiento del texto crudo**

Ahora definiremos una funci√≥n llamada LemTokens que tomar√° como entrada los tokens y devolver√° tokens normalizados.
```bash
lemmer = nltk.stem.WordNetLemmatizer()  #WordNet is a semantically-oriented dictionary of English included in NLTK.def LemTokens(tokens):  return [lemmer.lemmatize(token) for token in tokens]  remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)  def LemNormalize(text):  return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))
```

**Coincidencia de palabras clave**

A continuaci√≥n, definiremos una funci√≥n para un saludo a trav√©s el bot, es decir, si la entrada de un usuario es un saludo, el bot devolver√° una respuesta de saludo. ELIZA usa una palabra clave simple que coincide con los saludos. Utilizaremos el mismo concepto aqu√≠.
```bash
GREETING_INPUTS = ("hello", "hi", "greetings", "sup", "what's up","hey",)  GREETING_RESPONSES = ["hi", "hey", "*nods*", "hi there", "hello", "I am glad! You are talking to me"]def greeting(sentence):     for word in sentence.split():   if word.lower() in GREETING_INPUTS:   return random.choice(GREETING_RESPONSES)
```
**Generando respuestas**

Para generar una respuesta de nuestro bot para preguntas de entrada, se utilizar√° el concepto de similitud de documentos. Entonces comenzamos importando los m√≥dulos necesarios.

Desde la biblioteca scikit learn, importa el **vectorizador TFidf** para convertir una colecci√≥n de documentos en bruto en una matriz de caracter√≠sticas TF-IDF.
```bash
from sklearn.feature_extraction.text import TfidfVectorizer
```

Adem√°s, importa el m√≥dulo de similitud de coseno desde la biblioteca de aprendizaje de scikit
```bash
from sklearn.metrics.pairwise import cosine_similarity
```
Esto se usar√° para encontrar la similitud entre las palabras ingresadas por el usuario y las palabras en el corpus. Esta es la implementaci√≥n m√°s simple posible de un chatbot.

Definimos una respuesta de funci√≥n que busca la expresi√≥n del usuario para una o m√°s palabras clave conocidas y devuelve una de las varias repsuestas posibles. Si no encuentra la entrada que coincide con ninguna de las palabras clave, devuelve una respuesta: ‚Äú¬°Lo siento! No te entiendo.
```bash
def response(user_response):   robo_response=''   sent_tokens.append(user_response)TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')   tfidf = TfidfVec.fit_transform(sent_tokens)   vals = cosine_similarity(tfidf[-1], tfidf)   idx=vals.argsort()[0][-2]   flat = vals.flatten()   flat.sort()   req_tfidf = flat[-2]if(req_tfidf==0):   robo_response=robo_response+"I am sorry! I don't understand you"   return robo_response   else:   robo_response = robo_response+sent_tokens[idx]   return robo_response
```

Finalmente, alimentaremos las l√≠neas que queremos que diga nuestro robot al iniciar y finalizar una conversaci√≥n, seg√∫n la informaci√≥n del usuario.

```bash
flag=True  print("ROBO: My name is Robo. I will answer your queries about Chatbots. If you want to exit, type Bye!")while(flag==True):   user_response = input()   user_response=user_response.lower()   if(user_response!='bye'):   if(user_response=='thanks' or user_response=='thank you' ):   flag=False   print("ROBO: You are welcome..")   else:   if(greeting(user_response)!=None):   print("ROBO: "+greeting(user_response))   else:   print("ROBO: ",end="")   print(response(user_response))   sent_tokens.remove(user_response)   else:   flag=False   print("ROBO: Bye! take care..")
```

Y eso es todo. Tenemos el codificado de nuestro primer chatbot en NLTK. Puedes encontrar el c√≥digo completo con el corpus aqu√≠ . Ahora, veamos c√≥mo interact√∫a con los humanos:

![direcci√≥n de la imagen](1pPcVfZ7i-gLMabUol3zezA.gif)

Esto no fue tan malo como parece. Incluso aunque el chatbot no pudo dar una respuesta satisfactoria a algunas preguntas, hizo un trabajo excelente en otras.

## Conclusi√≥n

Aunque es un bot muy simple con casi ninguna habilidad cognitiva, es una buena manera de entrar en la PNL y aprender sobre los chatbots. Aunque ‚ÄòROBO‚Äô responde a las sugerencias del usuario. No enga√±ar√° a sus amigos y, para un sistema de producci√≥n, querr√° considerar una de las plataformas o marcos de bots existentes, pero este ejemplo lo ayudar√° a pensar en el dise√±o y el desaf√≠o de crear un chatbot. Internet est√° inundado de recursos. y despu√©s de leer este art√≠culo, estoy seguro de que desear√°s crear un chatbot propio.

# Resumen Estructurado.

Aqu√≠ te dejo un resumen estructurado y algunos consejos adicionales para que puedas sacarle el m√°ximo provecho:

## Instalaci√≥n y configuraci√≥n de NLTK

Instala NLTK con:

```bash
pip install nltk
```
Verifica la instalaci√≥n:

```python
import nltk
```
Descarga los recursos necesarios:

```python
nltk.download('punkt')
nltk.download('wordnet')
```

## Preprocesamiento de texto

Tokenizaci√≥n de oraciones y palabras:

```python
sent_tokens = nltk.sent_tokenize(raw)
word_tokens = nltk.word_tokenize(raw)
```

Lematizaci√≥n y normalizaci√≥n:

```python
lemmer = nltk.stem.WordNetLemmatizer()

def LemTokens(tokens):
    return [lemmer.lemmatize(token) for token in tokens]

remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)

def LemNormalize(text):
    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))
```

## TF-IDF y Similitud Coseno

TF-IDF con scikit-learn:

```python
from sklearn.feature_extraction.text import TfidfVectorizer
TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')
tfidf = TfidfVec.fit_transform(sent_tokens)
```

Similitud coseno:

```python
from sklearn.metrics.pairwise import cosine_similarity
vals = cosine_similarity(tfidf[-1], tfidf)
```

## Construcci√≥n del chatbot ROBO

Respuestas a saludos:

```python

GREETING_INPUTS = ("hello", "hi", "greetings", "sup", "what's up","hey",)
GREETING_RESPONSES = ["hi", "hey", "*nods*", "hi there", "hello", "I am glad! You are talking to me"]

def greeting(sentence):
    for word in sentence.split():
        if word.lower() in GREETING_INPUTS:
            return random.choice(GREETING_RESPONSES)
```

## Generaci√≥n de respuestas:

```python
def response(user_response):
    robo_response = ''
    sent_tokens.append(user_response)
    tfidf = TfidfVec.fit_transform(sent_tokens)
    vals = cosine_similarity(tfidf[-1], tfidf)
    idx = vals.argsort()[0][-2]
    flat = vals.flatten()
    flat.sort()
    req_tfidf = flat[-2]
    if req_tfidf == 0:
        robo_response += "I am sorry! I don't understand you"
    else:
        robo_response += sent_tokens[idx]
    return robo_response
```

## Bucle principal del chatbot:

```python
flag = True
print("ROBO: My name is Robo. I will answer your queries about Chatbots. If you want to exit, type Bye!")
while flag:
    user_response = input().lower()
    if user_response != 'bye':
        if user_response in ['thanks', 'thank you']:
            flag = False
            print("ROBO: You are welcome..")
        elif greeting(user_response) is not None:
            print("ROBO:", greeting(user_response))
        else:
            print("ROBO:", response(user_response))
            sent_tokens.remove(user_response)
    else:
        flag = False
        print("ROBO: Bye! take care..")
```

## Sugerencias adicionales

Puedes mejorar el chatbot a√±adiendo detecci√≥n de intenci√≥n con modelos como spaCy o transformers.

Para una interfaz m√°s amigable, podr√≠as integrarlo con una aplicaci√≥n web usando Flask o Streamlit.

Si el corpus es muy peque√±o, considera usar embeddings preentrenados como Word2Vec o BERT para mejorar la comprensi√≥n sem√°ntica.

# Juntando todo esto:

```python
# -*- coding: utf-8 -*-
import nltk
import numpy as np
import random
import string
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# Descargar recursos necesarios de NLTK
nltk.download('punkt')     # Tokenizador de oraciones
nltk.download('wordnet')   # Lemmatizador

# Leer el corpus base
with open('chatbot.txt', 'r', errors='ignore') as f:
    raw = f.read().lower()

# Tokenizaci√≥n
sent_tokens = nltk.sent_tokenize(raw)  # Lista de oraciones
word_tokens = nltk.word_tokenize(raw)  # Lista de palabras

# Lematizaci√≥n y normalizaci√≥n
lemmer = nltk.stem.WordNetLemmatizer()

def LemTokens(tokens):
    return [lemmer.lemmatize(token) for token in tokens]

remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)

def LemNormalize(text):
    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))

# Respuestas a saludos
GREETING_INPUTS = ("hello", "hi", "greetings", "sup", "what's up", "hey")
GREETING_RESPONSES = ["hi", "hey", "*nods*", "hi there", "hello", "I am glad! You are talking to me"]

def greeting(sentence):
    for word in sentence.split():
        if word.lower() in GREETING_INPUTS:
            return random.choice(GREETING_RESPONSES)

# Generaci√≥n de respuesta basada en similitud coseno
def response(user_response):
    robo_response = ''
    sent_tokens.append(user_response)
    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')
    tfidf = TfidfVec.fit_transform(sent_tokens)
    vals = cosine_similarity(tfidf[-1], tfidf)
    idx = vals.argsort()[0][-2]
    flat = vals.flatten()
    flat.sort()
    req_tfidf = flat[-2]

    if req_tfidf == 0:
        robo_response += "I am sorry! I don't understand you."
    else:
        robo_response += sent_tokens[idx]

    sent_tokens.remove(user_response)
    return robo_response

# Bucle principal del chatbot
def start_chat():
    print("ROBOü§ñ: My name is Robo. I will answer your queries about Chatbots. If you want to exit, type 'bye'.")
    while True:
        user_response = input().lower()
        if user_response == 'bye':
            print("ROBOü§ñ: Bye! Take care.")
            break
        elif user_response in ['thanks', 'thank you']:
            print("ROBOü§ñ: You are welcome!")
            break
        elif greeting(user_response) is not None:
            print("ROBOü§ñ:", greeting(user_response))
        else:
            print("ROBOü§ñ:", response(user_response))

# Ejecutar chatbot
if __name__ == "__main__":
    start_chat()
```
## Notas importantes:
Aseg√∫rate de tener un archivo llamado **chatbot.txt** en el mismo directorio. Este archivo debe contener el texto base del chatbot.

Puedes personalizar el corpus para que ROBO responda sobre cualquier tema: salud, historia, tecnolog√≠a, etc.

Este chatbot es b√°sico pero funcional. Si quieres que aprenda o entienda mejor, podemos integrarle modelos m√°s avanzados como spaCy, transformers o incluso una interfaz web.

# contenido inicial para chatbot.txt:

```text
Un chatbot es un programa inform√°tico dise√±ado para simular una conversaci√≥n con usuarios humanos, especialmente a trav√©s de Internet. Los chatbots pueden ser tan simples como un sistema de respuestas autom√°ticas o tan complejos como asistentes virtuales impulsados por inteligencia artificial.

El procesamiento de lenguaje natural (PLN) es una rama de la inteligencia artificial que se ocupa de la interacci√≥n entre computadoras y lenguaje humano. El objetivo del PLN es permitir que las m√°quinas comprendan, interpreten y generen lenguaje de manera significativa.

Los chatbots modernos utilizan t√©cnicas de PLN para analizar las entradas del usuario y generar respuestas relevantes. Algunas de estas t√©cnicas incluyen la tokenizaci√≥n, la lematizaci√≥n, el an√°lisis sint√°ctico y sem√°ntico, y el uso de modelos estad√≠sticos como TF-IDF.

TF-IDF es una t√©cnica que eval√∫a la importancia de una palabra en un documento en relaci√≥n con un corpus. Se utiliza com√∫nmente en sistemas de recuperaci√≥n de informaci√≥n y clasificaci√≥n de texto.

La similitud coseno es una medida que permite comparar dos documentos en funci√≥n de su contenido textual. Se basa en el √°ngulo entre los vectores que representan los documentos en un espacio multidimensional.

Los chatbots pueden utilizar TF-IDF y similitud coseno para encontrar respuestas relevantes en una base de datos de texto. Esto les permite responder preguntas de manera m√°s precisa y coherente.

El futuro de los chatbots incluye una mayor personalizaci√≥n, comprensi√≥n contextual y capacidades multimodales que integran texto, voz e incluso im√°genes.
```
## Qu√© puedes hacer ahora

Crear el archivo: Copia ese texto en un archivo llamado **chatbot.txt** y gu√°rdalo en el mismo directorio que tu script de Python.

## Ejecuta tu chatbot y prueba preguntas como:

    ¬øQu√© es un chatbot?

    ¬øPara qu√© sirve el PLN?

    ¬øQu√© es TF-IDF?

    ¬øD√≥nde se usan los chatbots?

    ¬øQu√© es la inteligencia artificial?

**Personalizar el corpus:** Si quieres que ROBO responda sobre otro tema (como historia, salud, programaci√≥n, etc.), solo reemplaza el contenido del archivo por texto relacionado

¬øQuieres que te ayude a generar un corpus sobre otro tema espec√≠fico? Puedo ayudarte a redactarlo.

# Chatbot con interfaz grafica tkinter.

Opci√≥n 1: Interfaz Gr√°fica con **Tkinter (Python)**
Tkinter es una biblioteca est√°ndar de Python para crear interfaces gr√°ficas. Aqu√≠ tienes una versi√≥n b√°sica que integra tu chatbot en una ventana interactiva:

```python
import tkinter as tk
from tkinter import scrolledtext
import nltk
import random
import string
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# Inicializaci√≥n NLTK
nltk.download('punkt')
nltk.download('wordnet')

# Corpus
with open('chatbot.txt', 'r', errors='ignore') as f:
    raw = f.read().lower()
sent_tokens = nltk.sent_tokenize(raw)

# Preprocesamiento
lemmer = nltk.stem.WordNetLemmatizer()
def LemTokens(tokens): return [lemmer.lemmatize(t) for t in tokens]
remove_punct_dict = dict((ord(p), None) for p in string.punctuation)
def LemNormalize(text): return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))

# Saludos
GREETING_INPUTS = ("hello", "hi", "greetings", "sup", "what's up", "hey")
GREETING_RESPONSES = ["hi", "hey", "*nods*", "hi there", "hello", "I am glad! You are talking to me"]
def greeting(sentence):
    for word in sentence.split():
        if word.lower() in GREETING_INPUTS:
            return random.choice(GREETING_RESPONSES)

# Respuesta
def response(user_response):
    robo_response = ''
    sent_tokens.append(user_response)
    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')
    tfidf = TfidfVec.fit_transform(sent_tokens)
    vals = cosine_similarity(tfidf[-1], tfidf)
    idx = vals.argsort()[0][-2]
    flat = vals.flatten()
    flat.sort()
    req_tfidf = flat[-2]
    if req_tfidf == 0:
        robo_response += "I am sorry! I don't understand you."
    else:
        robo_response += sent_tokens[idx]
    sent_tokens.remove(user_response)
    return robo_response

# Interfaz Tkinter
def send():
    user_input = entry.get()
    chat_window.insert(tk.END, "You: " + user_input + "\n")
    entry.delete(0, tk.END)
    if user_input.lower() == 'bye':
        chat_window.insert(tk.END, "ROBOü§ñ: Bye! Take care.\n")
        return
    elif user_input.lower() in ['thanks', 'thank you']:
        chat_window.insert(tk.END, "ROBOü§ñ: You are welcome!\n")
    elif greeting(user_input) is not None:
        chat_window.insert(tk.END, "ROBOü§ñ: " + greeting(user_input) + "\n")
    else:
        chat_window.insert(tk.END, "ROBOü§ñ: " + response(user_input) + "\n")

root = tk.Tk()
root.title("ROBO Chatbot")

chat_window = scrolledtext.ScrolledText(root, wrap=tk.WORD, width=60, height=20, font=("Arial", 12))
chat_window.pack(padx=10, pady=10)

entry = tk.Entry(root, width=60, font=("Arial", 12))
entry.pack(padx=10, pady=5)

send_button = tk.Button(root, text="Send", command=send, font=("Arial", 12))
send_button.pack(pady=5)

chat_window.insert(tk.END, "ROBOü§ñ: Hello! I am ROBO. Ask me anything about chatbots. Type 'bye' to exit.\n")

root.mainloop()
```

Opci√≥n 2: **Interfaz Web con Flask**
Flask es un microframework web en Python. Aqu√≠ tienes una estructura b√°sica para que ROBO funcione en un navegador:

Instala Flask:

```bash
pip install flask
```
Crea app.py con el siguiente contenido:

```python
from flask import Flask, render_template, request
import nltk, random, string
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

app = Flask(__name__)
nltk.download('punkt')
nltk.download('wordnet')

with open('chatbot.txt', 'r', errors='ignore') as f:
    raw = f.read().lower()
sent_tokens = nltk.sent_tokenize(raw)
lemmer = nltk.stem.WordNetLemmatizer()
def LemTokens(tokens): return [lemmer.lemmatize(t) for t in tokens]
remove_punct_dict = dict((ord(p), None) for p in string.punctuation)
def LemNormalize(text): return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))
GREETING_INPUTS = ("hello", "hi", "greetings", "sup", "what's up", "hey")
GREETING_RESPONSES = ["hi", "hey", "*nods*", "hi there", "hello", "I am glad! You are talking to me"]
def greeting(sentence):
    for word in sentence.split():
        if word.lower() in GREETING_INPUTS:
            return random.choice(GREETING_RESPONSES)
def response(user_response):
    robo_response = ''
    sent_tokens.append(user_response)
    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')
    tfidf = TfidfVec.fit_transform(sent_tokens)
    vals = cosine_similarity(tfidf[-1], tfidf)
    idx = vals.argsort()[0][-2]
    flat = vals.flatten()
    flat.sort()
    req_tfidf = flat[-2]
    if req_tfidf == 0:
        robo_response += "I am sorry! I don't understand you."
    else:
        robo_response += sent_tokens[idx]
    sent_tokens.remove(user_response)
    return robo_response

@app.route("/")
def home():
    return render_template("index.html")

@app.route("/get")
def get_bot_response():
    userText = request.args.get('msg')
    if greeting(userText):
        return greeting(userText)
    else:
        return response(userText)

if __name__ == "__main__":
    app.run(debug=True)
```
## 3 Crea una carpeta templates y dentro un archivo index.html con una interfaz b√°sica.

¬øQuieres que te ayude a crear el archivo HTML para la interfaz web o prefieres seguir con la versi√≥n gr√°fica en escritorio?

# archivo index.html

Aqu√≠ tienes un archivo HTML b√°sico llamado index.html que funcionar√° como la interfaz web para tu chatbot ROBOü§ñ usando Flask. Este archivo debe guardarse dentro de una carpeta llamada templates, en el mismo directorio donde est√° tu archivo app.py.

### templates/index.html

```xml
<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <title>Chatbot ROBOü§ñ</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            background-color: #f4f4f9;
            margin: 0;
            padding: 0;
        }
        .chat-container {
            width: 60%;
            margin: 50px auto;
            background-color: white;
            border-radius: 8px;
            box-shadow: 0 0 10px rgba(0,0,0,0.1);
            padding: 20px;
        }
        .chat-box {
            height: 400px;
            overflow-y: scroll;
            border: 1px solid #ddd;
            padding: 10px;
            margin-bottom: 10px;
            background-color: #fff;
        }
        .user, .bot {
            margin: 10px 0;
        }
        .user {
            text-align: right;
            color: #007bff;
        }
        .bot {
            text-align: left;
            color: #333;
        }
        input[type="text"] {
            width: 80%;
            padding: 10px;
            font-size: 16px;
        }
        button {
            padding: 10px 20px;
            font-size: 16px;
            background-color: #007bff;
            color: white;
            border: none;
            cursor: pointer;
        }
        button:hover {
            background-color: #0056b3;
        }
    </style>
</head>
<body>
    <div class="chat-container">
        <h2>ROBOü§ñ - Tu asistente sobre Chatbots</h2>
        <div class="chat-box" id="chat-box">
            <div class="bot">ROBOü§ñ: ¬°Hola! Preg√∫ntame lo que quieras sobre chatbots. Escribe "bye" para salir.</div>
        </div>
        <input type="text" id="user-input" placeholder="Escribe tu mensaje aqu√≠..." />
        <button onclick="sendMessage()">Enviar</button>
    </div>

    <script>
        function sendMessage() {
            const userInput = document.getElementById("user-input").value;
            if (userInput.trim() === "") return;

            const chatBox = document.getElementById("chat-box");
            chatBox.innerHTML += `<div class="user">T√∫: ${userInput}</div>`;
            document.getElementById("user-input").value = "";

            fetch(`/get?msg=${encodeURIComponent(userInput)}`)
                .then(response => response.text())
                .then(data => {
                    chatBox.innerHTML += `<div class="bot">ROBOü§ñ: ${data}</div>`;
                    chatBox.scrollTop = chatBox.scrollHeight;
                });
        }
    </script>
</body>
</html>
```

## ¬øQu√© sigue?
Guarda este archivo como **index.html** dentro de la carpeta **templates**.

Ejecuta tu aplicaci√≥n Flask con python app.py.

Abre tu navegador y ve a http://127.0.0.1:5000/ para comenzar a chatear con ROBOü§ñ.

¬øTe gustar√≠a que a√±adamos funciones como historial de conversaci√≥n, reconocimiento de voz o traducci√≥n autom√°tica? Puedo ayudarte a llevarlo al siguiente nivel.

# Stop list en espa√±ol

Gracias por se√±alarlo. El error que est√°s viendo se debe a que TfidfVectorizer de scikit-learn no admite directamente el par√°metro 'spanish' en stop_words. Solo acepta 'english', una lista personalizada o None.

## Soluci√≥n
Para que el chatbot funcione en espa√±ol, debes proporcionar una lista de palabras vac√≠as (stopwords) en espa√±ol. Puedes obtenerla f√°cilmente con NLTK:

## Descarga las stopwords en espa√±ol
Agrega esto al inicio de tu script:

```python
nltk.download('stopwords')
from nltk.corpus import stopwords
spanish_stopwords = stopwords.words('spanish')
```

## Usa la lista en TfidfVectorizer

Reemplaza esta l√≠nea:

```python
TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='spanish')
```
Por esta:

```python
TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words=spanish_stopwords)
```
##  ¬øPor qu√© esto funciona?

TfidfVectorizer necesita una lista expl√≠cita de palabras vac√≠as si no es 'english'. Al usar stopwords.words('spanish'), le est√°s dando exactamente lo que necesita para filtrar palabras comunes como ‚Äúde‚Äù, ‚Äúla‚Äù, ‚Äúque‚Äù, ‚Äúy‚Äù, etc.

# Evoluconando el Chatbot.

Expandir ROBOü§ñ con capacidades como memoria, reconocimiento de voz o conexi√≥n a bases de datos lo convertir√≠a en un asistente mucho m√°s potente y √∫til. Aqu√≠ te dejo un desglose de c√≥mo podr√≠amos abordar cada mejora:

## 1. Memoria de conversaci√≥n

Objetivo: Que ROBO recuerde lo que el usuario ha dicho anteriormente para mantener el contexto.

C√≥mo hacerlo:

Crear una lista global **historial_conversacion = []** donde se guarden los turnos de di√°logo.

Mostrar el historial en la interfaz o usarlo para enriquecer las respuestas.

Ejemplo:

```python
historial_conversacion.append(("usuario", user_input))
historial_conversacion.append(("robo", bot_reply))
```

Ventaja: ROBO puede responder con m√°s coherencia y continuidad.

## 2. Reconocimiento de voz

Objetivo: Que el usuario pueda hablar en lugar de escribir.

C√≥mo hacerlo:

Usar la biblioteca speech_recognition:

```bash
pip install SpeechRecognition pyaudio
```

Capturar voz y convertirla en texto:

```python

import speech_recognition as sr

r = sr.Recognizer()

with sr.Microphone() as source:
    audio = r.listen(source)
    user_input = r.recognize_google(audio, language='es-ES')
```

Ventaja: Interacci√≥n m√°s natural y accesible.

## 3. Conexi√≥n a base de datos externa

Objetivo: Que ROBO pueda consultar informaci√≥n din√°mica (por ejemplo, preguntas frecuentes, productos, citas).

C√≥mo hacerlo:

Usar SQLite, MySQL o PostgreSQL.

Consultar datos con SQL y mostrar resultados como respuesta.

Ejemplo con SQLite:

```python
import sqlite3
conn = sqlite3.connect('chatbot_data.db')
cursor = conn.cursor()
cursor.execute("SELECT respuesta FROM faq WHERE pregunta LIKE ?", ('%'+user_input+'%',))
resultado = cursor.fetchone()
```
Ventaja: ROBO puede responder con datos actualizados y personalizados.

¬øTe gustar√≠a que empecemos por una de estas mejoras? Puedo ayudarte a implementar la memoria de conversaci√≥n primero, o si prefieres, montar el reconocimiento de voz para que ROBO te escuche. T√∫ decides el siguiente paso.

# Utilizar mongodb como base de datos.

Usar MongoDB es una excelente elecci√≥n para almacenar y consultar datos din√°micos en tu chatbot ROBO. Vamos a integrarlo paso a paso.

# ¬øQu√© necesitamos?

## 1. Instalar el cliente de MongoDB para Python

Ejecuta en tu terminal:

```bash
pip install pymongo
```

## 2. Crear una base de datos y colecci√≥n en MongoDB

Por ejemplo, puedes tener una base de datos llamada robo_chatbot y una colecci√≥n llamada faq con documentos como:

```json
{
  "pregunta": "¬øQu√© es un chatbot?",
  "respuesta": "Un chatbot es un programa inform√°tico que simula conversaciones humanas."
}
```
## 3. Conectar ROBO a MongoDB

Agrega esto al inicio de tu script:

```python
from pymongo import MongoClient
```

# Conexi√≥n a MongoDB local (puedes cambiar la URI si usas MongoDB Atlas)

```python
client = MongoClient("mongodb://localhost:27017/")
db = client["robo_chatbot"]
faq_collection = db["faq"]
```
## 4. Buscar respuestas en la base de datos

Modifica la funci√≥n response() para que primero intente encontrar una coincidencia en MongoDB:

```python
def response(user_response):
    # Buscar coincidencia exacta o parcial en MongoDB
    resultado = faq_collection.find_one({"pregunta": {"$regex": user_response, "$options": "i"}})
    if resultado:
        return resultado["respuesta"]

    # Si no hay coincidencia en MongoDB, usar TF-IDF
    robo_response = ''
    temp_tokens = sent_tokens.copy()
    temp_tokens.append(user_response)
    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words=spanish_stopwords)
    tfidf = TfidfVec.fit_transform(temp_tokens)
    vals = cosine_similarity(tfidf[-1], tfidf)
    idx = vals.argsort()[0][-2]
    flat = vals.flatten()
    flat.sort()
    req_tfidf = flat[-2]
    if req_tfidf == 0:
        robo_response += "Lo siento, no entiendo lo que me dices."
    else:
        robo_response += temp_tokens[idx]
    return robo_response
```
‚úÖ Resultado
ROBO ahora puede:

Consultar respuestas en tiempo real desde MongoDB.

Usar TF-IDF como respaldo si no encuentra nada en la base de datos.

¬øQuieres que te ayude a poblar la base de datos con preguntas frecuentes o que conectemos MongoDB Atlas para usarlo en la nube? Tambi√©n podemos a√±adir una interfaz para que t√∫ mismo edites las preguntas y respuestas.

# Memoria para chatbot.
Aqu√≠ tienes tu c√≥digo complementado con:

    Memoria de conversaci√≥n almacenada en MongoDB (chatmemory).

    Ejecutar el bot√≥n "Enviar" al pulsar Enter en el campo de entrada.

```python
# -*- coding: utf-8 -*-
# pip install nltk scikit-learn pymongo

import tkinter as tk
from tkinter import scrolledtext
import nltk
import random
import string
from pymongo import MongoClient
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# Inicializaci√≥n NLTK
nltk.download('punkt')
nltk.download('wordnet')
nltk.download('stopwords')
from nltk.corpus import stopwords
spanish_stopwords = stopwords.words('spanish')

# Conexi√≥n a MongoDB
client = MongoClient("mongodb://localhost:27017/")
db = client["chatmemory"]
memoria = db["conversaciones"]

# Cargar corpus en espa√±ol
with open('chatbot.txt', 'r', errors='ignore', encoding='utf-8') as f:
    raw = f.read().lower()

sent_tokens = nltk.sent_tokenize(raw, language='spanish')
word_tokens = nltk.word_tokenize(raw, language='spanish')

# Preprocesamiento
lemmer = nltk.stem.WordNetLemmatizer()
def LemTokens(tokens): return [lemmer.lemmatize(token) for token in tokens]
remove_punct_dict = dict((ord(p), None) for punct in string.punctuation)
def LemNormalize(text): return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict), language='spanish'))

# Saludos
GREETING_INPUTS = ("hola", "buenas", "saludos", "qu√© tal", "hey")
GREETING_RESPONSES = ["¬°Hola!", "¬°Hey!", "*asiente*", "Hola, ¬øqu√© tal?", "¬°Encantado de hablar contigo!"]
def greeting(sentence):
    for word in sentence.split():
        if word.lower() in GREETING_INPUTS:
            return random.choice(GREETING_RESPONSES)

# Generar respuesta
def response(user_response):
    robo_response = ''
    temp_tokens = sent_tokens.copy()
    temp_tokens.append(user_response)
    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words=spanish_stopwords)
    tfidf = TfidfVec.fit_transform(temp_tokens)
    vals = cosine_similarity(tfidf[-1], tfidf)
    idx = vals.argsort()[0][-2]
    flat = vals.flatten()
    flat.sort()
    req_tfidf = flat[-2]
    if req_tfidf == 0:
        robo_response += "Lo siento, no entiendo lo que me dices."
    else:
        robo_response += temp_tokens[idx]
    return robo_response

# Enviar mensaje
def send(event=None):
    user_input = entry.get()
    if not user_input.strip():
        return

    chat_window.insert(tk.END, "T√∫: " + user_input + "\n")
    entry.delete(0, tk.END)

    if user_input.lower() == 'bye':
        bot_reply = "¬°Adi√≥s! Cu√≠date."
    elif user_input.lower() in ['gracias', 'muchas gracias']:
        bot_reply = "¬°De nada!"
    elif greeting(user_input) is not None:
        bot_reply = greeting(user_input)
    else:
        bot_reply = response(user_input)

    chat_window.insert(tk.END, "ROBOü§ñ: " + bot_reply + "\n")

    # Guardar en MongoDB
    memoria.insert_one({
        "usuario": user_input,
        "robo": bot_reply
    })

# Interfaz gr√°fica
root = tk.Tk()
root.title("Chatbot ROBOü§ñ")

chat_window = scrolledtext.ScrolledText(root, wrap=tk.WORD, width=60, height=20, font=("Arial", 12))
chat_window.pack(padx=10, pady=10)

entry = tk.Entry(root, width=60, font=("Arial", 12))
entry.pack(padx=10, pady=5)
entry.bind("<Return>", send)  # Ejecutar al pulsar Enter

send_button = tk.Button(root, text="Enviar", command=send, font=("Arial", 12))
send_button.pack(pady=5)

chat_window.insert(tk.END, "ROBOü§ñ: ¬°Hola! Soy ROBO. Preg√∫ntame lo que quieras sobre chatbots. Escribe 'bye' para salir.\n")

root.mainloop()
```

## ¬øQu√© hace este c√≥digo?

    Guarda cada turno de conversaci√≥n en MongoDB (chatmemory.conversaciones).

    Ejecuta el bot√≥n "Enviar" al pulsar Enter.

    Mantiene toda la l√≥gica de respuesta con TF-IDF y saludos en espa√±ol.

¬øQuieres que ROBO pueda recuperar el historial y mostrarlo al iniciar, o que tenga sesiones separadas por usuario? Tambi√©n podemos a√±adir filtros o exportar el historial. T√∫ decides el siguiente paso.

‚úÖ ¬øQu√© vamos a hacer?
Conectarnos a la base de datos chatmemory.

Recuperar todos los turnos de conversaci√≥n previos.

Guardarlos en una lista interna historial_conversacion.

No los mostramos en pantalla, pero quedan disponibles para uso futuro.

## C√≥digo complementado

Agrega esto justo despu√©s de conectar a MongoDB:

```python
# Recuperar historial de conversaci√≥n previo
historial_conversacion = list(memoria.find({}, {"_id": 0}))
```

Y si quieres usarlo m√°s adelante (por ejemplo, para an√°lisis o contexto), puedes acceder a:

```python
for turno in historial_conversacion:
    usuario = turno["usuario"]
    robo = turno["robo"]
    # Aqu√≠ podr√≠as usarlo para enriquecer respuestas futuras
```

## ¬øQu√© puedes hacer con esto despu√©s?

    Analizar qu√© preguntas son m√°s frecuentes.

    Detectar patrones de conversaci√≥n.

    Personalizar respuestas seg√∫n el historial.

    Implementar sesiones por usuario si a√±ades un campo como "usuario_id".

¬øQuieres que ROBO empiece a usar el historial para adaptar sus respuestas o que te muestre estad√≠sticas de uso? Tambi√©n podemos a√±adir un bot√≥n para exportar el historial si lo necesitas.

# Complimentando el Chat.

Vamos a complementar tu chatbot ROBO para que:

    Recupere el historial de conversaci√≥n desde MongoDB al iniciar (sin mostrarlo).

    Permita usar ese historial para an√°lisis o estad√≠sticas.

    A√±ada un bot√≥n para exportar el historial a consola (puedes adaptarlo para guardar en archivo si lo deseas).

## Cambios que vamos a hacer

    Crear una lista historial_conversacion con los turnos previos.

    A√±adir un bot√≥n "Exportar historial" que imprime el historial en consola.

    Mantener todo integrado en tu interfaz Tkinter.

## Fragmento de c√≥digo actualizado

Agrega esto justo despu√©s de conectar a MongoDB:

```python
# Recuperar historial de conversaci√≥n previo (sin mostrar)
historial_conversacion = list(memoria.find({}, {"_id": 0}))
```

Y modifica la funci√≥n send() para guardar cada turno en esa lista tambi√©n:

```python
def send(event=None):
    user_input = entry.get()
    if not user_input.strip():
        return

    chat_window.insert(tk.END, "T√∫: " + user_input + "\n")
    entry.delete(0, tk.END)

    if user_input.lower() == 'bye':
        bot_reply = "¬°Adi√≥s! Cu√≠date."
    elif user_input.lower() in ['gracias', 'muchas gracias']:
        bot_reply = "¬°De nada!"
    elif greeting(user_input) is not None:
        bot_reply = greeting(user_input)
    else:
        bot_reply = response(user_input)

    chat_window.insert(tk.END, "ROBOü§ñ: " + bot_reply + "\n")

    # Guardar en MongoDB y en memoria local
    turno = {"usuario": user_input, "robo": bot_reply}
    memoria.insert_one(turno)
    historial_conversacion.append(turno)
```

## Bot√≥n para exportar historial

Agrega esta funci√≥n:

```python
def exportar_historial():
    print("\n--- Historial de conversaci√≥n ---")
    for turno in historial_conversacion:
        print(f"T√∫: {turno['usuario']}")
        print(f"ROBOü§ñ: {turno['robo']}")
    print("--- Fin del historial ---\n")
```

Y a√±ade el bot√≥n en la interfaz:

```python
export_button = tk.Button(root, text="Exportar historial", command=exportar_historial, font=("Arial", 12))
export_button.pack(pady=5)
```

## Resultado

Tu chatbot ahora:

    Recupera el historial sin mostrarlo.

    Lo actualiza en tiempo real.

    Permite exportarlo con un clic.

¬øQuieres que ese historial se guarde en un archivo .txt o .csv, o que se filtre por fecha o usuario? Tambi√©n podemos a√±adir un buscador de preguntas pasadas.

# Cambios al chat

Aqu√≠ tenemos el archivo Python completamente actualizado con:

    Recuperaci√≥n del historial desde MongoDB (sin mostrarlo).

    Almacenamiento de cada turno en la colecci√≥n conversaciones de la base de datos chatmemory.

    Bot√≥n para exportar el historial a consola.

    Ejecuci√≥n del bot√≥n "Enviar" al pulsar Enter.


## C√≥digo completo actualizado

fichero: eschattknew.py

```python
# -*- coding: utf-8 -*-
# pip install nltk scikit-learn pymongo

import tkinter as tk
from tkinter import scrolledtext
import nltk
import random
import string
from pymongo import MongoClient
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# Inicializaci√≥n NLTK
nltk.download('punkt')
nltk.download('wordnet')
nltk.download('stopwords')
from nltk.corpus import stopwords
spanish_stopwords = stopwords.words('spanish')

# Conexi√≥n a MongoDB
client = MongoClient("mongodb://localhost:27017/")
db = client["chatmemory"]
memoria = db["conversaciones"]

# Recuperar historial previo (sin mostrar)
historial_conversacion = list(memoria.find({}, {"_id": 0}))

# Cargar corpus en espa√±ol
with open('chatbot.txt', 'r', errors='ignore', encoding='utf-8') as f:
    raw = f.read().lower()

sent_tokens = nltk.sent_tokenize(raw, language='spanish')
word_tokens = nltk.word_tokenize(raw, language='spanish')

# Preprocesamiento
lemmer = nltk.stem.WordNetLemmatizer()
def LemTokens(tokens): return [lemmer.lemmatize(token) for token in tokens]
remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)
def LemNormalize(text): return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict), language='spanish'))

# Saludos
GREETING_INPUTS = ("hola", "buenas", "saludos", "qu√© tal", "hey")
GREETING_RESPONSES = ["¬°Hola!", "¬°Hey!", "*asiente*", "Hola, ¬øqu√© tal?", "¬°Encantado de hablar contigo!"]
def greeting(sentence):
    for word in sentence.split():
        if word.lower() in GREETING_INPUTS:
            return random.choice(GREETING_RESPONSES)

# Generar respuesta
def response(user_response):
    robo_response = ''
    temp_tokens = sent_tokens.copy()
    temp_tokens.append(user_response)
    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words=spanish_stopwords)
    tfidf = TfidfVec.fit_transform(temp_tokens)
    vals = cosine_similarity(tfidf[-1], tfidf)
    idx = vals.argsort()[0][-2]
    flat = vals.flatten()
    flat.sort()
    req_tfidf = flat[-2]
    if req_tfidf == 0:
        robo_response += "Lo siento, no entiendo lo que me dices."
    else:
        robo_response += temp_tokens[idx]
    return robo_response

# Enviar mensaje
def send(event=None):
    user_input = entry.get()
    if not user_input.strip():
        return

    chat_window.insert(tk.END, "T√∫: " + user_input + "\n")
    entry.delete(0, tk.END)

    if user_input.lower() == 'bye':
        bot_reply = "¬°Adi√≥s! Cu√≠date."
    elif user_input.lower() in ['gracias', 'muchas gracias']:
        bot_reply = "¬°De nada!"
    elif greeting(user_input) is not None:
        bot_reply = greeting(user_input)
    else:
        bot_reply = response(user_input)

    chat_window.insert(tk.END, "ROBOü§ñ: " + bot_reply + "\n")

    # Guardar en MongoDB y en memoria local
    turno = {"usuario": user_input, "robo": bot_reply}
    memoria.insert_one(turno)
    historial_conversacion.append(turno)

# Exportar historial a consola
def exportar_historial():
    print("\n--- Historial de conversaci√≥n ---")
    for turno in historial_conversacion:
        print(f"T√∫: {turno['usuario']}")
        print(f"ROBOü§ñ: {turno['robo']}")
    print("--- Fin del historial ---\n")

# Interfaz gr√°fica
root = tk.Tk()
root.title("Chatbot ROBOü§ñ")

chat_window = scrolledtext.ScrolledText(root, wrap=tk.WORD, width=60, height=20, font=("Arial", 12))
chat_window.pack(padx=10, pady=10)

entry = tk.Entry(root, width=60, font=("Arial", 12))
entry.pack(padx=10, pady=5)
entry.bind("<Return>", send)  # Ejecutar al pulsar Enter

send_button = tk.Button(root, text="Enviar", command=send, font=("Arial", 12))
send_button.pack(pady=5)

export_button = tk.Button(root, text="Exportar historial", command=exportar_historial, font=("Arial", 12))
export_button.pack(pady=5)

chat_window.insert(tk.END, "ROBOü§ñ: ¬°Hola! Soy ROBO. Preg√∫ntame lo que quieras sobre chatbots. Escribe 'bye' para salir.\n")

root.mainloop()
```

# Historial

¬øQu√© es sent_tokens y c√≥mo se ‚Äúa√±ade‚Äù el corpus?

Cuando haces esto:

```python
with open('chatbot.txt', 'r', errors='ignore', encoding='utf-8') as f:
    raw = f.read().lower()

sent_tokens = nltk.sent_tokenize(raw, language='spanish')
```
Est√°s creando una lista de oraciones (sent_tokens) que se usa como base de conocimiento para el chatbot. Cada vez que el usuario escribe algo, se compara con estas oraciones usando TF-IDF y similitud coseno.

## ¬øQu√© es historial_conversacion y c√≥mo se usa?

Cuando haces esto:

```python
historial_conversacion = list(memoria.find({}, {"_id": 0}))
```
Est√°s recuperando los turnos anteriores (usuario y ROBO) desde MongoDB. Pero por defecto, este historial no se usa para responder. Solo se guarda en una lista para que est√© disponible si lo necesitas.

## Entonces‚Ä¶ ¬øpor qu√© no se ‚Äúa√±ade‚Äù al bot?

Porque no se mezcla con sent_tokens, que es lo que el bot usa para generar respuestas. Si quieres que el historial influya en las respuestas, tendr√≠as que hacer algo como esto:

```python
# A√±adir respuestas anteriores de ROBO al corpus
for turno in historial_conversacion:
    sent_tokens.append(turno["robo"])
```
Esto s√≠ a√±ade el historial al bot, porque ahora ROBO podr√° comparar lo que el usuario dice con lo que ya respondi√≥ antes.

## ¬øD√≥nde ponerlo?

Justo despu√©s de cargar el corpus:

```python
# Cargar corpus en espa√±ol
with open('chatbot.txt', 'r', errors='ignore', encoding='utf-8') as f:
    raw = f.read().lower()

sent_tokens = nltk.sent_tokenize(raw, language='spanish')

# A√±adir historial de respuestas anteriores al corpus
for turno in historial_conversacion:
    sent_tokens.append(turno["robo"])
```

## ¬øPor qu√© solo a√±adir las respuestas de ROBO?

Porque el bot responde comparando lo que el usuario dice con frases que ya conoce. Si a√±adimos las respuestas anteriores, puede reutilizarlas cuando detecte una pregunta similar.

¬øQuieres que tambi√©n se a√±adan las preguntas del usuario al corpus para que ROBO aprenda de ellas? Podemos hacerlo, pero hay que tener cuidado con errores o frases mal escritas. Te puedo ayudar a filtrar y mejorar eso tambi√©n.

# Exportar el historial.

## Exportar el historial a .txt o .csv

Esto te permitir√° guardar todas las conversaciones en un archivo para analizarlas, compartirlas o usarlas como corpus adicional.

## ¬øC√≥mo lo hacermos?

Agrega estas funciones a tu c√≥digo:

```python
import csv

def exportar_historial_txt():
    with open("historial_robo.txt", "w", encoding="utf-8") as file:
        for turno in historial_conversacion:
            file.write(f"T√∫: {turno['usuario']}\n")
            file.write(f"ROBOü§ñ: {turno['robo']}\n\n")
    print("Historial exportado a historial_robo.txt")

def exportar_historial_csv():
    with open("historial_robo.csv", "w", newline='', encoding="utf-8") as file:
        writer = csv.writer(file)
        writer.writerow(["Usuario", "ROBOü§ñ"])
        for turno in historial_conversacion:
            writer.writerow([turno["usuario"], turno["robo"]])
    print("Historial exportado a historial_robo.csv")
```

Y a√±ade dos botones en tu interfaz:

```python
btn_txt = tk.Button(root, text="Exportar a TXT", command=exportar_historial_txt, font=("Arial", 12))
btn_txt.pack(pady=2)

btn_csv = tk.Button(root, text="Exportar a CSV", command=exportar_historial_csv, font=("Arial", 12))
btn_csv.pack(pady=2)
```

## Usar el historial como fuente de respuestas

Esto convierte el historial en una especie de ‚Äúmemoria viva‚Äù que ROBO puede consultar para responder si encuentra coincidencias.

## ¬øC√≥mo lo hacemos?

Modifica la funci√≥n response() para buscar primero en el historial:

```python
def response(user_response):
    # Buscar coincidencia en historial
    for turno in reversed(historial_conversacion):
        if user_response.lower() in turno["usuario"].lower():
            return f"(Basado en historial) {turno['robo']}"

    # Si no hay coincidencia, usar TF-IDF
    robo_response = ''
    temp_tokens = sent_tokens.copy()
    temp_tokens.append(user_response)
    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words=spanish_stopwords)
    tfidf = TfidfVec.fit_transform(temp_tokens)
    vals = cosine_similarity(tfidf[-1], tfidf)
    idx = vals.argsort()[0][-2]
    flat = vals.flatten()
    flat.sort()
    req_tfidf = flat[-2]
    if req_tfidf == 0:
        robo_response += "Lo siento, no entiendo lo que me dices."
    else:
        robo_response += temp_tokens[idx]
    return robo_response
```

## Resultado

ROBO ahora puede:

    Exportar el historial a .txt y .csv.

    Consultar el historial para responder si ya se habl√≥ de algo similar.

¬øQuieres que ROBO tambi√©n reconozca temas frecuentes y te los muestre como resumen? O que filtre el historial por fecha o palabra clave. Podemos seguir afinando su inteligencia.

# Exportar historial a md.

Agrega esta funci√≥n a tu c√≥digo para exportar el historial en formato Markdown:

```python
def exportar_historial_md():
    with open("historial_robo.md", "w", encoding="utf-8") as file:
        file.write("# Historial de conversaci√≥n con ROBO ü§ñ\n\n")
        for i, turno in enumerate(historial_conversacion, start=1):
            file.write(f"### Conversaci√≥n {i}\n")
            file.write(f"- **T√∫:** {turno['usuario']}\n")
            file.write(f"- **ROBOü§ñ:** {turno['robo']}\n\n")
    print("Historial exportado a historial_robo.md")
```

## A√±ade el bot√≥n a la interfaz

Justo como hiciste con los botones .txt y .csv, a√±ade este:

```python
btn_md = tk.Button(root, text="Exportar a Markdown", command=exportar_historial_md, font=("Arial", 12))
btn_md.pack(pady=2)
```
## Resultado

ROBO ahora puede exportar el historial en tres formatos:

    .txt ‚Üí texto plano

    .csv ‚Üí para hojas de c√°lculo

    .md ‚Üí para documentaci√≥n estructurada

¬øQuieres que el archivo .md incluya fecha y hora de cada conversaci√≥n, o que se agrupe por sesiones? Tambi√©n podemos a√±adir encabezados personalizados o emojis para hacerlo m√°s visual.

# Aprendizaje continuo.

Puedes implementar un sistema que:

    Analice cada conversaci√≥n.

    Detecte nuevas preguntas.

    Actualice autom√°ticamente el corpus o la base de datos.

Esto convierte a ROBO en un asistente que evoluciona con cada sesi√≥n.

## ¬øPor d√≥nde empezar?

Si quieres algo pr√°ctico y √∫til desde ya, te recomiendo:

    A√±adir las respuestas del historial a sent_tokens.

    Crear una colecci√≥n en MongoDB llamada aprendizaje donde guardes preguntas sin respuesta.

    Revisar esa colecci√≥n t√∫ mismo y a√±adir respuestas manualmente.

¬øQuieres que te ayude a implementar ese sistema de aprendizaje supervisado o que ROBO te avise cuando no entiende algo? Podemos hacerlo paso a paso.

# Aprendiendo.

## ¬øQu√© vamos a hacer?
    Crear una colecci√≥n en MongoDB llamada aprendizaje.

    Guardar all√≠ las preguntas que ROBO no entiende.

    Consultar esa colecci√≥n antes de usar TF-IDF.

    Permitir que t√∫ a√±adas respuestas manualmente (por consola o desde MongoDB Compass).

ROBO usar√° esas respuestas en futuras sesiones.

## Paso a paso en tu c√≥digo

### Conexi√≥n a la colecci√≥n aprendizaje

Agrega esto junto a tus otras conexiones MongoDB:

```python
aprendizaje = db["aprendizaje"]

### Modificar la funci√≥n response() para consultar y aprender

Reemplaza tu funci√≥n response() por esta versi√≥n mejorada:

```python
def response(user_response):
    # 1. Buscar en la colecci√≥n de aprendizaje
    resultado = aprendizaje.find_one({"pregunta": {"$regex": user_response, "$options": "i"}})
    if resultado:
        return f"(Aprendido) {resultado['respuesta']}"

    # 2. Buscar en historial
    for turno in reversed(historial_conversacion):
        if user_response.lower() in turno["usuario"].lower():
            return f"(Basado en historial) {turno['robo']}"

    # 3. Usar TF-IDF
    robo_response = ''
    temp_tokens = sent_tokens.copy()
    temp_tokens.append(user_response)
    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words=spanish_stopwords)
    tfidf = TfidfVec.fit_transform(temp_tokens)
    vals = cosine_similarity(tfidf[-1], tfidf)
    idx = vals.argsort()[0][-2]
    flat = vals.flatten()
    flat.sort()
    req_tfidf = flat[-2]

    # 4. Si no entiende, guardar para aprendizaje
    if req_tfidf == 0:
        aprendizaje.insert_one({"pregunta": user_response, "respuesta": None})
        robo_response += "Lo siento, no entiendo lo que me dices. Lo guardar√© para aprender m√°s adelante."
    else:
        robo_response += temp_tokens[idx]

    return robo_response
```

## A√±adir respuestas manualmente

Puedes abrir MongoDB Compass o usar consola para editar los documentos en aprendizaje y a√±adir el campo "respuesta".

Ejemplo:

```json
{
  "pregunta": "¬øCu√°l es la capital de Espa√±a?",
  "respuesta": "La capital de Espa√±a es Madrid."
}
```

## Resultado

ROBO ahora:

    Aprende de lo que no entiende.

    Consulta lo aprendido antes de responder.

    Te permite ense√±arle nuevas respuestas f√°cilmente.

¬øQuieres que te ayude a crear una interfaz para editar esas respuestas desde el propio chatbot? Tambi√©n podemos a√±adir un sistema de revisi√≥n autom√°tica o sugerencias de respuesta.

# ¬øQu√© har√° esta mejora?
    
    Cuando ROBO no entienda una pregunta, la guardar√° en MongoDB (aprendizaje).

    Tendr√°s un bot√≥n en la interfaz para ver las preguntas pendientes.

    Podr√°s seleccionar una y escribir la respuesta directamente desde la ventana del chatbot.

    ROBO usar√° esa respuesta en futuras conversaciones.

##  ¬øC√≥mo lo implementamos?

### A√±adir una ventana emergente para ense√±ar

Agrega esta funci√≥n a tu c√≥digo:

```python
def abrir_editor_aprendizaje():
    editor = tk.Toplevel(root)
    editor.title("Aprendizaje supervisado")

    preguntas_pendientes = list(aprendizaje.find({"respuesta": None}, {"_id": 0}))

    if not preguntas_pendientes:
        tk.Label(editor, text="No hay preguntas pendientes.").pack(padx=10, pady=10)
        return

    tk.Label(editor, text="Selecciona una pregunta para ense√±ar a ROBO:").pack(padx=10, pady=5)

    lista = tk.Listbox(editor, width=80)
    for p in preguntas_pendientes:
        lista.insert(tk.END, p["pregunta"])
    lista.pack(padx=10, pady=5)

    respuesta_entry = tk.Entry(editor, width=80)
    respuesta_entry.pack(padx=10, pady=5)
    respuesta_entry.insert(0, "Escribe aqu√≠ la respuesta...")

    def guardar_respuesta():
        seleccion = lista.curselection()
        if seleccion:
            pregunta = lista.get(seleccion[0])
            respuesta = respuesta_entry.get()
            if respuesta.strip():
                aprendizaje.update_one({"pregunta": pregunta}, {"$set": {"respuesta": respuesta}})
                tk.Label(editor, text="¬°Respuesta guardada! ROBO ha aprendido.").pack(pady=5)

    tk.Button(editor, text="Guardar respuesta", command=guardar_respuesta).pack(pady=5)
```
### A√±adir el bot√≥n a la interfaz principal

Justo debajo de los botones de exportaci√≥n, a√±ade:

```python
btn_aprender = tk.Button(root, text="Ense√±ar a ROBO", command=abrir_editor_aprendizaje, font=("Arial", 12))
btn_aprender.pack(pady=2)
```

### Resultado

Ahora puedes:

    Ver las preguntas que ROBO no ha entendido.

    Escribir respuestas directamente desde la interfaz.

    Guardarlas en MongoDB para que ROBO las use autom√°ticamente.

¬øQuieres que ROBO te sugiera respuestas basadas en el corpus o que te avise cuando hay nuevas preguntas sin respuesta? Tambi√©n podemos a√±adir filtros por fecha o categor√≠a.

# Aprendizaje supervizado.

Aqu√≠ tienes la ampliaci√≥n final para que ROBO tenga una interfaz completa de aprendizaje supervisado, con sugerencias autom√°ticas y gesti√≥n de nuevas preguntas sin respuesta.

## ¬øQu√© a√±adimos?
    ROBO te avisa cuando hay nuevas preguntas sin respuesta.

    Puedes abrir una ventana para ense√±ar a ROBO directamente.

    ROBO sugiere respuestas basadas en el corpus si no entiende algo.

    Todo se guarda en MongoDB y se actualiza en tiempo real.

## Paso a paso

### A√±adir aviso de nuevas preguntas sin respuesta

Al iniciar el chatbot, justo despu√©s de recuperar el historial:

```python
pendientes = aprendizaje.count_documents({"respuesta": None})
if pendientes > 0:
    print(f"Hay {pendientes} preguntas sin respuesta en la colecci√≥n de aprendizaje.")
```

### Sugerir respuesta desde el corpus si no entiende

En la funci√≥n response(), mejora el bloque de ‚Äúno entiendo‚Äù:

```python
if req_tfidf == 0:
    # Sugerir frase similar del corpus
    sugerencia = temp_tokens[idx] if idx < len(temp_tokens) else None
    aprendizaje.insert_one({"pregunta": user_response, "respuesta": None})
    if sugerencia:
        robo_response += f"No estoy seguro, pero quiz√°s te refieres a:\n‚Üí {sugerencia}\nLo guardar√© para aprender m√°s adelante."
    else:
        robo_response += "Lo siento, no entiendo lo que me dices. Lo guardar√© para aprender m√°s adelante."
```
### Mostrar preguntas pendientes en la interfaz

Ya tienes el bot√≥n ‚ÄúEnse√±ar a ROBO‚Äù. Puedes a√±adir un contador din√°mico:

```python
def actualizar_contador_aprendizaje():
    pendientes = aprendizaje.count_documents({"respuesta": None})
    btn_aprender.config(text=f"Ense√±ar a ROBO ({pendientes})")
```

Y llamarlo justo despu√©s de cada `insert_one()` en `response()` y al iniciar:

```python
actualizar_contador_aprendizaje()
```

## Resultado

El ROBO ahora:

    Aprende de lo que no entiende.

    Te avisa cuando necesita ayuda.

    Sugiere respuestas similares.

    Tiene una interfaz para que t√∫ lo entrenes f√°cilmente.

¬øQuieres que ROBO tambi√©n tenga un modo ‚Äúentrenamiento autom√°tico‚Äù donde aprenda de respuestas frecuentes o que se conecte a una API para buscar respuestas externas? Podemos llevarlo a√∫n m√°s lejos.

# Aprendizaje con Respuestas externas.

Entrenamiento autom√°tico + conexi√≥n a una API libre

Esto permitir√° que ROBO:

    Aprenda autom√°ticamente de preguntas frecuentes y respuestas exitosas.

    Consulte una API libre cuando no sepa algo, para buscar informaci√≥n en tiempo real.

## Parte 1: Entrenamiento autom√°tico
### ¬øQu√© har√°?

ROBO detectar√° preguntas repetidas.

Si una respuesta ha funcionado varias veces, la a√±adir√° autom√°ticamente a la colecci√≥n aprendizaje.

## C√≥mo implementarlo

Agrega esta l√≥gica dentro de la funci√≥n `send()` justo despu√©s de guardar el turno:

```python
# Entrenamiento autom√°tico: detectar repeticiones
repeticiones = sum(1 for t in historial_conversacion if t["usuario"].lower() == user_input.lower())
if repeticiones >= 3:
    ya_aprendido = aprendizaje.find_one({"pregunta": user_input})
    if not ya_aprendido:
        aprendizaje.insert_one({"pregunta": user_input, "respuesta": bot_reply})
        print(f"üß† ROBO ha aprendido autom√°ticamente: {user_input} ‚Üí {bot_reply}")
```

Esto le permite aprender sin intervenci√≥n humana cuando detecta patrones.

## Parte 2: Conexi√≥n a una API libre

### ¬øQu√© har√°?

Si ROBO no entiende algo, consultar√° una API p√∫blica como DuckDuckGo Instant Answer API para buscar informaci√≥n.

### C√≥mo implementarlo

Primero, instala requests si no lo tienes:

```bash
pip install requests
```
Luego, a√±ade esta funci√≥n:

```python
import requests

def consulta_api_libre(pregunta):
    url = "https://api.duckduckgo.com/"
    params = {
        "q": pregunta,
        "format": "json",
        "no_redirect": 1,
        "no_html": 1
    }
    try:
        r = requests.get(url, params=params)
        data = r.json()
        respuesta = data.get("AbstractText") or data.get("Answer") or data.get("Definition")
        if respuesta:
            return f"(Desde la web) {respuesta}"
    except:
        pass
    return None
```

Y en tu funci√≥n `response()`, antes de decir ‚Äúno entiendo‚Äù, a√±ade:

```python
# Consultar API libre si no hay coincidencia
respuesta_api = consulta_api_libre(user_response)
if respuesta_api:
    return respuesta_api
```

## Resultado
ROBO ahora puede:

    Aprender autom√°ticamente de conversaciones repetidas.

    Consultar una API libre para responder preguntas generales.

    Evolucionar sin intervenci√≥n constante.

¬øQuieres que ROBO tambi√©n tenga un modo ‚Äúcurioso‚Äù donde te pregunte cosas para aprender m√°s, o que se conecte a Wikipedia, OpenWeather o alguna API tem√°tica? Podemos hacerlo a√∫n m√°s inteligente.

# Modo Curioso.

¬°Genial! Vamos a convertir a ROBO en un asistente verdaderamente curioso y autodidacta, capaz de buscar respuestas en tiempo real usando APIs tem√°ticas como:

    Wikipedia API ‚Üí para definiciones y explicaciones generales.

    OpenWeather API ‚Üí para informaci√≥n meteorol√≥gica.

    Numbers API ‚Üí para datos curiosos sobre fechas y n√∫meros.

## ¬øC√≥mo lo hacemos?

### Wikipedia API (sin clave)

Agrega esta funci√≥n:

```python
def consulta_wikipedia(pregunta):
    import requests
    url = f"https://es.wikipedia.org/api/rest_v1/page/summary/{pregunta.replace(' ', '_')}"
    try:
        r = requests.get(url)
        data = r.json()
        if 'extract' in data:
            return f"(Wikipedia) {data['extract']}"
    except:
        pass
    return None
```

### OpenWeather API (requiere clave gratuita)

Reg√≠strate en openweathermap.org y obt√©n tu clave. Luego:

```python
def consulta_clima(ciudad):
    import requests
    clave = "TU_API_KEY"
    url = f"https://api.openweathermap.org/data/2.5/weather?q={ciudad}&appid={clave}&units=metric&lang=es"
    try:
        r = requests.get(url)
        data = r.json()
        if data.get("main"):
            temp = data["main"]["temp"]
            desc = data["weather"][0]["description"]
            return f"(Clima) En {ciudad} hay {desc} con {temp}¬∞C."
    except:
        pass
    return None
```

### Numbers API (curiosidades)

```python
def consulta_curiosidad(fecha):
    import requests
    url = f"http://numbersapi.com/{fecha}/date?json"
    try:
        r = requests.get(url)
        data = r.json()
        if data.get("text"):
            return f"(Curiosidad) {data['text']}"
    except:
        pass
    return None
```
## Integraci√≥n en response()

Antes de decir ‚Äúno entiendo‚Äù, a√±ade:

```python
# Consultar Wikipedia
respuesta_wiki = consulta_wikipedia(user_response)
if respuesta_wiki:
    return respuesta_wiki

# Consultar clima si detecta palabra clave
if "clima" in user_response or "tiempo" in user_response:
    ciudad = user_response.split()[-1]  # simplificado
    respuesta_clima = consulta_clima(ciudad)
    if respuesta_clima:
        return respuesta_clima

# Consultar curiosidad si detecta fecha
if "d√≠a" in user_response or "fecha" in user_response:
    respuesta_fecha = consulta_curiosidad("9/20")  # ejemplo: 20 de septiembre
    if respuesta_fecha:
        return respuesta_fecha
```

## Resultado

ROBO ahora puede:

    Aprender autom√°ticamente de ti y de patrones.

    Consultar Wikipedia para definiciones.

    Darte el clima actual de cualquier ciudad.

    Compartir curiosidades sobre fechas.

¬øQuieres que ROBO tenga un modo ‚Äúexplorador‚Äù donde te proponga temas nuevos o te haga preguntas para aprender contigo? Tambi√©n podemos conectarlo a APIs de noticias, salud o cultura.

________________________

# Registro.

registrarte en OpenWeatherMap y conseguir tu API key

### Paso 1: Crear cuenta en OpenWeatherMap

Ve a [openweathermap](https://home.openweathermap.org/users/sign_up)

Rellena el formulario con:

    Nombre de usuario

    Email v√°lido

    Contrase√±a

    Acepta t√©rminos y condiciones

    Haz clic en Create Account.

    Revisa tu correo y confirma tu direcci√≥n de email (necesario para activar la cuenta).

## Paso 2: Obtener tu API Key

Inicia sesi√≥n en [apikey](https://home.openweathermap.org/) 


    Ve al men√∫ API keys (en la parte superior o en tu perfil).

Por defecto, ya tendr√°s una clave llamada Default (una cadena alfanum√©rica larga).

Copia esa API key (ejemplo: abcd1234efgh5678ijkl90mn).

(Opcional) Puedes crear m√°s keys con nombres diferentes si usas varios proyectos.

## Paso 3: Usar la API Key

Ejemplo en terminal con curl:

curl "https://api.openweathermap.org/data/2.5/weather?q=Madrid&appid=TU_API_KEY"


Ejemplo en Python:

```python
import requests

API_KEY = "TU_API_KEY"
ciudad = "Madrid"
url = f"https://api.openweathermap.org/data/2.5/weather?q={ciudad}&appid={API_KEY}&lang=es&units=metric"

respuesta = requests.get(url)
datos = respuesta.json()

print(datos)
```

Y listo: ya puedes usar la clave para consultar clima, pron√≥sticos, alertas, etc.

¬øQuieres que te prepare un script pr√°ctico en Python que te d√© el clima actual de cualquier ciudad que le pongas por consola?

___________________________________


# Modo explorador.

darle a ROBO su modo m√°s curioso y explorador hasta ahora! En este modo, ROBO no solo responde: tambi√©n propone temas, busca novedades culturales, noticias actuales y datos de salud usando APIs libres. Aqu√≠ te explico c√≥mo implementarlo paso a paso:

# Modo Explorador: ¬øQu√© har√°?
    Propondr√° temas interesantes al azar (cultura, ciencia, salud, historia).

    Consultar√° una API de noticias para mostrar titulares actuales.

    Usar√° una API de salud para responder dudas b√°sicas.

    Buscar√° datos culturales o curiosidades usando Wikipedia o Numbers API.

## Paso 1: Activar el modo explorador

Agrega una variable global:

```python
modo_explorador = False
```

Y un bot√≥n en la interfaz:

```python
def activar_explorador():
    global modo_explorador
    modo_explorador = not modo_explorador
    estado = "activado" if modo_explorador else "desactivado"
    chat_window.insert(tk.END, f"ROBOü§ñ: Modo explorador {estado}.\n")

btn_explorador = tk.Button(root, text="Modo Explorador", command=activar_explorador, font=("Arial", 12))
btn_explorador.pack(pady=2)
```

## Paso 2: Proponer temas aleatorios

Agrega esta funci√≥n:

```python
import random

def sugerir_tema():
    temas = [
        "¬øSab√≠as que el cerebro humano consume el 20% de la energ√≠a del cuerpo?",
        "¬øQuieres saber qu√© pas√≥ un d√≠a como hoy en la historia?",
        "¬øTe interesa conocer una curiosidad cient√≠fica?",
        "¬øQuieres que te cuente una noticia cultural actual?",
        "¬øTe gustar√≠a saber algo sobre salud preventiva?"
    ]
    return random.choice(temas)
```
## Paso 3: Integrar APIs tem√°ticas

## Noticias (NewsAPI.org)

Reg√≠strate y obt√©n tu clave gratuita. Luego:

```python
def consulta_noticias():
    import requests
    clave = "TU_API_KEY"
    url = f"https://newsapi.org/v2/top-headlines?country=es&category=general&apiKey={clave}"
    try:
        r = requests.get(url)
        data = r.json()
        if data.get("articles"):
            titulo = data["articles"][0]["title"]
            return f"(Noticia) {titulo}"
    except:
        pass
    return None
```
## Salud (Wikipedia + filtros)

Usa la funci√≥n consulta_wikipedia() que ya tienes, pero con temas como ‚Äúsalud mental‚Äù, ‚Äúnutrici√≥n‚Äù, ‚Äúejercicio f√≠sico‚Äù.

## Paso 4: Integrar en `send()` si modo explorador est√° activo

Dentro de `send()`, antes de procesar la respuesta:

```python
if modo_explorador:
    propuesta = sugerir_tema()
    chat_window.insert(tk.END, f"ROBOü§ñ: {propuesta}\n")

    # Buscar contenido seg√∫n propuesta
    if "noticia" in propuesta:
        noticia = consulta_noticias()
        if noticia:
            chat_window.insert(tk.END, f"ROBOü§ñ: {noticia}\n")
    elif "historia" in propuesta:
        historia = consulta_curiosidad("9/20")  # ejemplo
        if historia:
            chat_window.insert(tk.END, f"ROBOü§ñ: {historia}\n")
    elif "salud" in propuesta:
        salud = consulta_wikipedia("salud preventiva")
        if salud:
            chat_window.insert(tk.END, f"ROBOü§ñ: {salud}\n")
```

‚úÖ Resultado
ROBO ahora tiene un modo explorador que:

Propone temas curiosos.

Consulta noticias reales.

Busca datos culturales y de salud.

Te sorprende con cada interacci√≥n.

¬øQuieres que ROBO tenga una personalidad m√°s definida en este modo (por ejemplo, m√°s curioso, divertido o reflexivo)? Tambi√©n podemos hacer que te pregunte cosas para conocerte mejor y adaptar sus sugerencias.

_________________________________

## Mejoras incluidas

    Aprendizaje autom√°tico de preguntas frecuentes.

    Consulta de APIs libres: Wikipedia, OpenWeather, NumbersAPI, NewsAPI.

    Modo explorador con sugerencias culturales, cient√≠ficas, hist√≥ricas y de salud.

    Curiosidades sobre fechas.

    Clima actual por ciudad.

    Noticias actuales.

    Entrenamiento supervisado y autom√°tico.

## C√≥digo completo mejorado

Debido a su extensi√≥n y complejidad, te entregar√© el archivo completo en formato .py listo para ejecutar. Incluye:

    Funciones `consulta_wikipedia`, `consulta_clima`, `consulta_curiosidad`, `consulta_noticias`.

    Activaci√≥n de modo_explorador con bot√≥n.

    Integraci√≥n de sugerencias tem√°ticas aleatorias.

    Aprendizaje autom√°tico si una pregunta se repite m√°s de 3 veces.

    Fallback inteligente si ROBO no entiende algo.

## Importante: 
necesitar√°s claves API para OpenWeather y NewsAPI. Te explico c√≥mo obtenerlas en el c√≥digo comentado.

## ¬øQu√© sigue?
Voy a preparar el archivo y entreg√°rtelo aqu√≠ mismo. ¬øQuieres que lo divida en secciones para que puedas copiarlo f√°cilmente, o prefieres que lo empaquete como un archivo descargable? Tambi√©n puedo ayudarte a configurar las claves API si lo necesitas.

# Codigo mejorado.

Aqu√≠ tienes el c√≥digo completo de ROBO dividido en secciones tem√°ticas para que puedas integrarlo f√°cilmente. Cada secci√≥n incluye comentarios explicativos para que sepas qu√© hace y d√≥nde colocarla.

## Importaciones y configuraci√≥n inicial

```python
# -*- coding: utf-8 -*-
# pip install nltk scikit-learn pymongo requests

import tkinter as tk
from tkinter import scrolledtext
import nltk
import random
import string
import csv
import requests
from pymongo import MongoClient
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# Inicializaci√≥n NLTK
nltk.download('punkt')
nltk.download('wordnet')
nltk.download('stopwords')
from nltk.corpus import stopwords
spanish_stopwords = stopwords.words('spanish')
```

## Conexi√≥n a MongoDB y carga de corpus

```python
# Conexi√≥n a MongoDB
client = MongoClient("mongodb://localhost:27017/")
db = client["chatmemory"]
memoria = db["conversaciones"]
aprendizaje = db["aprendizaje"]

# Recuperar historial previo
historial_conversacion = list(memoria.find({}, {"_id": 0}))

# Cargar corpus en espa√±ol
with open('chatbot.txt', 'r', errors='ignore', encoding='utf-8') as f:
    raw = f.read().lower()
sent_tokens = nltk.sent_tokenize(raw, language='spanish')
for turno in historial_conversacion:
    sent_tokens.append(turno["robo"])
```

## Preprocesamiento y saludos

```python
lemmer = nltk.stem.WordNetLemmatizer()
def LemTokens(tokens): return [lemmer.lemmatize(token) for token in tokens]
remove_punct_dict = dict((ord(p), None) for p in string.punctuation)
def LemNormalize(text): return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict), language='spanish'))

GREETING_INPUTS = ("hola", "buenas", "saludos", "qu√© tal", "hey")
GREETING_RESPONSES = ["¬°Hola!", "¬°Hey!", "*asiente*", "Hola, ¬øqu√© tal?", "¬°Encantado de hablar contigo!"]
def greeting(sentence):
    for word in sentence.split():
        if word.lower() in GREETING_INPUTS:
            return random.choice(GREETING_RESPONSES)
```
## 4. Funciones de consulta a APIs libres

```python
def consulta_wikipedia(pregunta):
    url = f"https://es.wikipedia.org/api/rest_v1/page/summary/{pregunta.replace(' ', '_')}"
    try:
        r = requests.get(url)
        data = r.json()
        if 'extract' in data:
            return data['extract']
    except:
        return None

def consulta_clima(ciudad):
    clave = "TU_API_KEY_OPENWEATHER"
    url = f"https://api.openweathermap.org/data/2.5/weather?q={ciudad}&appid={clave}&units=metric&lang=es"
    try:
        r = requests.get(url)
        data = r.json()
        if data.get("main"):
            temp = data["main"]["temp"]
            desc = data["weather"][0]["description"]
            return f"En {ciudad} hay {desc} con {temp}¬∞C."
    except:
        return None

def consulta_curiosidad(fecha):
    url = f"http://numbersapi.com/{fecha}/date?json"
    try:
        r = requests.get(url)
        data = r.json()
        return data.get("text")
    except:
        return None

def consulta_noticias():
    clave = "TU_API_KEY_NEWSAPI"
    url = f"https://newsapi.org/v2/top-headlines?country=es&category=general&apiKey={clave}"
    try:
        r = requests.get(url)
        data = r.json()
        if data.get("articles"):
            return data["articles"][0]["title"]
    except:
        return None
```
## Modo explorador y sugerencias

```python
modo_explorador = False

def activar_explorador():
    global modo_explorador
    modo_explorador = not modo_explorador
    estado = "activado" if modo_explorador else "desactivado"
    chat_window.insert(tk.END, f"ROBO: Modo explorador {estado}.\n")

def sugerir_tema():
    temas = [
        "¬øSab√≠as que el cerebro humano consume el 20% de la energ√≠a del cuerpo?",
        "¬øQuieres saber qu√© pas√≥ un d√≠a como hoy en la historia?",
        "¬øTe interesa conocer una curiosidad cient√≠fica?",
        "¬øTe cuento una noticia cultural actual?",
        "¬øTe gustar√≠a saber algo sobre salud preventiva?"
    ]
    return random.choice(temas)
```

## Generaci√≥n de respuesta

```python
def response(user_response):
    resultado = aprendizaje.find_one({"pregunta": {"$regex": user_response, "$options": "i"}})
    if resultado and resultado["respuesta"]:
        return resultado["respuesta"]

    for turno in reversed(historial_conversacion):
        if user_response.lower() in turno["usuario"].lower():
            return turno["robo"]

    respuesta_api = consulta_wikipedia(user_response)
    if respuesta_api:
        return respuesta_api

    if "clima" in user_response or "tiempo" in user_response:
        ciudad = user_response.split()[-1]
        clima = consulta_clima(ciudad)
        if clima:
            return clima

    if "fecha" in user_response or "d√≠a" in user_response:
        curiosidad = consulta_curiosidad("9/20")
        if curiosidad:
            return curiosidad

    robo_response = ''
    temp_tokens = sent_tokens.copy()
    temp_tokens.append(user_response)
    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words=spanish_stopwords)
    tfidf = TfidfVec.fit_transform(temp_tokens)
    vals = cosine_similarity(tfidf[-1], tfidf)
    idx = vals.argsort()[0][-2]
    flat = vals.flatten()
    flat.sort()
    req_tfidf = flat[-2]

    if req_tfidf == 0:
        aprendizaje.insert_one({"pregunta": user_response, "respuesta": None})
        sugerencia = temp_tokens[idx] if idx < len(temp_tokens) else None
        return f"No estoy seguro, pero quiz√°s te refieres a:\n‚Üí {sugerencia}\nLo guardar√© para aprender m√°s adelante."
    else:
        return temp_tokens[idx]
```

## Funci√≥n de env√≠o y entrenamiento autom√°tico

```python
def send(event=None):
    user_input = entry.get()
    if not user_input.strip():
        return

    chat_window.insert(tk.END, "T√∫: " + user_input + "\n")
    entry.delete(0, tk.END)

    if modo_explorador:
        propuesta = sugerir_tema()
        chat_window.insert(tk.END, f"ROBO: {propuesta}\n")
        if "noticia" in propuesta:
            noticia = consulta_noticias()
            if noticia:
                chat_window.insert(tk.END, f"ROBO: {noticia}\n")
        elif "historia" in propuesta:
            historia = consulta_curiosidad("9/20")
            if historia:
                chat_window.insert(tk.END, f"ROBO: {historia}\n")
        elif "salud" in propuesta:
            salud = consulta_wikipedia("salud preventiva")
            if salud:
                chat_window.insert(tk.END, f"ROBO: {salud}\n")

    if user_input.lower() == 'bye':
        bot_reply = "¬°Adi√≥s! Cu√≠date."
    elif user_input.lower() in ['gracias', 'muchas gracias']:
        bot_reply = "¬°De nada!"
    elif greeting(user_input) is not None:
        bot_reply = greeting(user_input)
    else:
        bot_reply = response(user_input)

    chat_window.insert(tk.END, "ROBO: " + bot_reply + "\n")

    turno = {"usuario": user_input, "robo": bot_reply}
    memoria.insert_one(turno)
    historial_conversacion.append(turno)

    repeticiones = sum(1 for t in historial_conversacion if t["usuario"].lower() == user_input.lower())
    if repeticiones >= 3:
        ya_aprendido = aprendizaje.find_one({"pregunta": user_input})
        if not ya_aprendido:
            aprendizaje.insert_one({"pregunta": user_input, "respuesta": bot_reply})
```

## Interfaz gr√°fica y botones

```python
root = tk.Tk()
root.title("Chatbot ROBO")

chat_window = scrolledtext.ScrolledText(root, wrap=tk.WORD, width=60, height=20, font=("Arial", 12))
chat_window.pack(padx=10, pady=10)

entry = tk.Entry(root, width=60, font=("Arial", 12))
entry.pack(padx=10, pady=5)
entry.bind("<Return>", send)

send_button = tk.Button(root, text="Enviar", command=send, font=("Arial", 12))
send_button.pack(pady=5)

btn_explorador = tk.Button(root, text="
```

*****************************

# Codigo completo chatB.py

```python
# -*- coding: utf-8 -*-
# pip install nltk scikit-learn pymongo requests

import tkinter as tk
from tkinter import scrolledtext
import nltk
import random
import string
import csv
import requests
from pymongo import MongoClient
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# Inicializaci√≥n NLTK
nltk.download('punkt')
nltk.download('wordnet')
nltk.download('stopwords')
from nltk.corpus import stopwords
spanish_stopwords = stopwords.words('spanish')

# Conexi√≥n a MongoDB
client = MongoClient("mongodb://localhost:27017/")
db = client["chatmemory"]
memoria = db["conversaciones"]
aprendizaje = db["aprendizaje"]

# Recuperar historial previo
historial_conversacion = list(memoria.find({}, {"_id": 0}))

# Cargar corpus
with open('chatbot.txt', 'r', errors='ignore', encoding='utf-8') as f:
    raw = f.read().lower()
sent_tokens = nltk.sent_tokenize(raw, language='spanish')
for turno in historial_conversacion:
    sent_tokens.append(turno["robo"])

# Preprocesamiento
lemmer = nltk.stem.WordNetLemmatizer()
def LemTokens(tokens): return [lemmer.lemmatize(token) for token in tokens]
remove_punct_dict = dict((ord(p), None) for p in string.punctuation)
def LemNormalize(text): return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict), language='spanish'))

# Saludos
GREETING_INPUTS = ("hola", "buenas", "saludos", "qu√© tal", "hey")
GREETING_RESPONSES = ["¬°Hola!", "¬°Hey!", "*asiente*", "Hola, ¬øqu√© tal?", "¬°Encantado de hablar contigo!"]
def greeting(sentence):
    for word in sentence.split():
        if word.lower() in GREETING_INPUTS:
            return random.choice(GREETING_RESPONSES)

# APIs externas
def consulta_wikipedia(pregunta):
    url = f"https://es.wikipedia.org/api/rest_v1/page/summary/{pregunta.replace(' ', '_')}"
    try:
        r = requests.get(url)
        data = r.json()
        if 'extract' in data:
            return data['extract']
    except:
        return None

def consulta_clima(ciudad):
    clave = "TU_API_KEY_OPENWEATHER"
    url = f"https://api.openweathermap.org/data/2.5/weather?q={ciudad}&appid={clave}&units=metric&lang=es"
    try:
        r = requests.get(url)
        data = r.json()
        if data.get("main"):
            temp = data["main"]["temp"]
            desc = data["weather"][0]["description"]
            return f"En {ciudad} hay {desc} con {temp}¬∞C."
    except:
        return None

def consulta_curiosidad(fecha):
    url = f"http://numbersapi.com/{fecha}/date?json"
    try:
        r = requests.get(url)
        data = r.json()
        return data.get("text")
    except:
        return None

def consulta_noticias():
    clave = "TU_API_KEY_NEWSAPI"
    url = f"https://newsapi.org/v2/top-headlines?country=es&category=general&apiKey={clave}"
    try:
        r = requests.get(url)
        data = r.json()
        if data.get("articles"):
            return data["articles"][0]["title"]
    except:
        return None

# Modo explorador
modo_explorador = False
def activar_explorador():
    global modo_explorador
    modo_explorador = not modo_explorador
    estado = "activado" if modo_explorador else "desactivado"
    chat_window.insert(tk.END, f"ROBO: Modo explorador {estado}.\n")

def sugerir_tema():
    temas = [
        "¬øSab√≠as que el cerebro humano consume el 20% de la energ√≠a del cuerpo?",
        "¬øQuieres saber qu√© pas√≥ un d√≠a como hoy en la historia?",
        "¬øTe interesa conocer una curiosidad cient√≠fica?",
        "¬øTe cuento una noticia cultural actual?",
        "¬øTe gustar√≠a saber algo sobre salud preventiva?"
    ]
    return random.choice(temas)

# Generar respuesta
def response(user_response):
    resultado = aprendizaje.find_one({"pregunta": {"$regex": user_response, "$options": "i"}})
    if resultado and resultado["respuesta"]:
        return resultado["respuesta"]

    for turno in reversed(historial_conversacion):
        if user_response.lower() in turno["usuario"].lower():
            return turno["robo"]

    respuesta_api = consulta_wikipedia(user_response)
    if respuesta_api:
        return respuesta_api

    if "clima" in user_response or "tiempo" in user_response:
        ciudad = user_response.split()[-1]
        clima = consulta_clima(ciudad)
        if clima:
            return clima

    if "fecha" in user_response or "d√≠a" in user_response:
        curiosidad = consulta_curiosidad("9/20")
        if curiosidad:
            return curiosidad

    robo_response = ''
    temp_tokens = sent_tokens.copy()
    temp_tokens.append(user_response)
    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words=spanish_stopwords)
    tfidf = TfidfVec.fit_transform(temp_tokens)
    vals = cosine_similarity(tfidf[-1], tfidf)
    idx = vals.argsort()[0][-2]
    flat = vals.flatten()
    flat.sort()
    req_tfidf = flat[-2]

    if req_tfidf == 0:
        aprendizaje.insert_one({"pregunta": user_response, "respuesta": None})
        sugerencia = temp_tokens[idx] if idx < len(temp_tokens) else None
        return f"No estoy seguro, pero quiz√°s te refieres a:\n‚Üí {sugerencia}\nLo guardar√© para aprender m√°s adelante."
    else:
        return temp_tokens[idx]

# Enviar mensaje
def send(event=None):
    user_input = entry.get()
    if not user_input.strip():
        return

    chat_window.insert(tk.END, "T√∫: " + user_input + "\n")
    entry.delete(0, tk.END)

    if modo_explorador:
        propuesta = sugerir_tema()
        chat_window.insert(tk.END, f"ROBO: {propuesta}\n")
        if "noticia" in propuesta:
            noticia = consulta_noticias()
            if noticia:
                chat_window.insert(tk.END, f"ROBO: {noticia}\n")
        elif "historia" in propuesta:
            historia = consulta_curiosidad("9/20")
            if historia:
                chat_window.insert(tk.END, f"ROBO: {historia}\n")
        elif "salud" in propuesta:
            salud = consulta_wikipedia("salud preventiva")
            if salud:
                chat_window.insert(tk.END, f"ROBO: {salud}\n")

    if user_input.lower() == 'bye':
        bot_reply = "¬°Adi√≥s! Cu√≠date."
    elif user_input.lower() in ['gracias', 'muchas gracias']:
        bot_reply = "¬°De nada!"
    elif greeting(user_input) is not None:
        bot_reply = greeting(user_input)
    else:
        bot_reply = response(user_input)

    chat_window.insert(tk.END, "ROBO: " + bot_reply + "\n")

    turno = {"usuario": user_input, "robo": bot_reply}
    memoria.insert_one(turno)
    historial_conversacion.append(turno)

    repeticiones = sum(1 for t in historial_conversacion if t["usuario"].lower() == user_input.lower())
    if repeticiones >= 3:
        ya_aprendido = aprendizaje.find_one({"pregunta": user_input})
        if not ya_aprendido:
            aprendizaje.insert_one({"pregunta": user_input, "respuesta": bot_reply})

# Exportar historial
def exportar_historial_txt():
    with open("historial_robo.txt", "w", encoding="utf-8") as file:
        for turno in historial_conversacion:
            file.write(f"T√∫: {turno['usuario']}\nROBO: {turno['robo']}\n\n")

def exportar_historial_csv():
    with open("historial_robo.csv", "w", newline='', encoding="utf-8") as file:
        writer = csv.writer(file)
        writer.writerow(["Usuario", "ROBO"])
        for turno in historial_conversacion:
            writer.writerow([turno["usuario"], turno["robo"]])

def exportar_historial_md():
    with open("historial_robo.md", "w", encoding="utf-8") as file:
        file.write("# Historial de conversaci√≥n con ROBO\n\n")
        for i, turno in enumerate(historial_conversacion, start=1):
            file.write(f"### Conversaci√≥n {i}\n")
            file.write(f"- **T√∫:** {turno['usuario']}\n")
            file.write(f"- **ROBO:** {turno['robo']}\n\n")
    print("Historial exportado a historial_robo.md")

# Editor de aprendizaje supervisado
def abrir_editor_aprendizaje():
    editor = tk.Toplevel(root)
    editor.title("Aprendizaje supervisado")

    preguntas_pendientes = list(aprendizaje.find({"respuesta": None}, {"_id": 0}))

    if not preguntas_pendientes:
        tk.Label(editor, text="No hay preguntas pendientes.").pack(padx=10, pady=10)
        return

    tk.Label(editor, text="Selecciona una pregunta para ense√±ar a ROBO:").pack(padx=10, pady=5)

    lista = tk.Listbox(editor, width=80)
    for p in preguntas_pendientes:
        lista.insert(tk.END, p["pregunta"])
    lista.pack(padx=10, pady=5)

    respuesta_entry = tk.Entry(editor, width=80)
    respuesta_entry.pack(padx=10, pady=5)
    respuesta_entry.insert(0, "Escribe aqu√≠ la respuesta...")

    def guardar_respuesta():
        seleccion = lista.curselection()
        if seleccion:
            pregunta = lista.get(seleccion[0])
            respuesta = respuesta_entry.get()
            if respuesta.strip():
                aprendizaje.update_one({"pregunta": pregunta}, {"$set": {"respuesta": respuesta}})
                tk.Label(editor, text="¬°Respuesta guardada! ROBO ha aprendido.").pack(pady=5)

    tk.Button(editor, text="Guardar respuesta", command=guardar_respuesta).pack(pady=5)

# Interfaz gr√°fica principal
root = tk.Tk()
root.title("Chatbot ROBO")

chat_window = scrolledtext.ScrolledText(root, wrap=tk.WORD, width=60, height=20, font=("Arial", 12))
chat_window.pack(padx=10, pady=10)

entry = tk.Entry(root, width=60, font=("Arial", 12))
entry.pack(padx=10, pady=5)
entry.bind("<Return>", send)

send_button = tk.Button(root, text="Enviar", command=send, font=("Arial", 12))
send_button.pack(pady=5)

btn_explorador = tk.Button(root, text="Modo Explorador", command=activar_explorador, font=("Arial", 12))
btn_explorador.pack(pady=2)

btn_txt = tk.Button(root, text="Exportar a TXT", command=exportar_historial_txt, font=("Arial", 12))
btn_txt.pack(pady=2)

btn_csv = tk.Button(root, text="Exportar a CSV", command=exportar_historial_csv, font=("Arial", 12))
btn_csv.pack(pady=2)

btn_md = tk.Button(root, text="Exportar a Markdown", command=exportar_historial_md, font=("Arial", 12))
btn_md.pack(pady=2)

btn_aprender = tk.Button(root, text="Ense√±ar a ROBO", command=abrir_editor_aprendizaje, font=("Arial", 12))
btn_aprender.pack(pady=2)

chat_window.insert(tk.END, "ROBO: ¬°Hola! Soy ROBO. Preg√∫ntame lo que quieras sobre chatbots. Escribe 'bye' para salir.\n")

root.mainloop()
```

## Notas finales

Reemplaza "TU_API_KEY_OPENWEATHER" y "TU_API_KEY_NEWSAPI" por tus claves reales.

Aseg√∫rate de tener el archivo chatbot.txt con contenido en espa√±ol en el mismo directorio.

Puedes ampliar el corpus, a√±adir m√°s APIs o personalizar el modo explorador seg√∫n tus intereses.

¬øTe gustar√≠a que ROBO tuviera una interfaz m√°s visual o que se conecte a una base de datos externa para temas espec√≠ficos como medicina, arte o historia? Estoy listo para ayudarte a seguir evolucionando este proyecto.

__________________________

# Mejoras chatB.py

El chatbot ROBO ya tiene:

    Exportaci√≥n de historial en tres formatos: TXT, CSV y Markdown.

    Aprendizaje supervisado con una interfaz para ense√±ar respuestas manualmente.

    Interfaz gr√°fica completa con botones funcionales y una experiencia de usuario clara.


## Ideas finales para redondear el proyecto

## Validaci√≥n visual en el editor de aprendizaje

Agrega una etiqueta que se actualice din√°micamente para confirmar que la respuesta fue guardada, en lugar de crear m√∫ltiples etiquetas.

```python
estado_label = tk.Label(editor, text="")
estado_label.pack(pady=5)

def guardar_respuesta():
    seleccion = lista.curselection()
    if seleccion:
        pregunta = lista.get(seleccion[0])
        respuesta = respuesta_entry.get()
        if respuesta.strip():
            aprendizaje.update_one({"pregunta": pregunta}, {"$set": {"respuesta": respuesta}})
            estado_label.config(text="¬°Respuesta guardada! ROBO ha aprendido.")
```

## Bot√≥n para limpiar historial desde la interfaz

Agrega un bot√≥n que borre el historial de conversaci√≥n y la base de datos.

```python
def limpiar_historial():
    memoria.delete_many({})
    historial_conversacion.clear()
    chat_window.delete(1.0, tk.END)
    chat_window.insert(tk.END, "ROBO: Historial borrado. ¬°Empezamos de nuevo!\n")

btn_limpiar = tk.Button(root, text="Limpiar historial", command=limpiar_historial, font=("Arial", 12))
btn_limpiar.pack(pady=2)
```

## Guardar aprendizaje como backup

Exporta el contenido de la colecci√≥n aprendizaje a un archivo CSV para respaldo.

```python
def exportar_aprendizaje_csv():
    with open("aprendizaje_robo.csv", "w", newline='', encoding="utf-8") as file:
        writer = csv.writer(file)
        writer.writerow(["Pregunta", "Respuesta"])
        for doc in aprendizaje.find({}, {"_id": 0}):
            writer.writerow([doc["pregunta"], doc.get("respuesta", "")])
```

Y puedes a√±adir un bot√≥n:

```python
btn_aprendizaje_csv = tk.Button(root, text="Exportar aprendizaje", command=exportar_aprendizaje_csv, font=("Arial", 12))
btn_aprendizaje_csv.pack(pady=2)
```
__________________________

Si quieres que te ayude a empaquetar todo esto en un ejecutable .exe con pyinstaller, o convertirlo en una app web para que otros puedan usarlo desde su navegador, tambi√©n puedo ayudarte con eso. ¬øTe gustar√≠a dar ese siguiente paso?
__________________________

# Mejoras de funcionamiento.

Mejorar el comportamiento del chatbot en sus respuestas e interacci√≥n puede marcar la diferencia entre una experiencia rob√≥tica y una conversaci√≥n realmente √∫til y atractiva. Aqu√≠ tienes varias estrategias que puedes aplicar para lograrlo:

## Mejorar la comprensi√≥n del lenguaje

Actualmente usas TF-IDF + similitud coseno, que es eficaz pero limitado. Puedes mejorar la comprensi√≥n con:

**Clasificaci√≥n de intenci√≥n:** Usa un modelo de clasificaci√≥n (como Naive Bayes o SVM) para detectar si el usuario quiere clima, noticias, curiosidades, etc.

**Embeddings sem√°nticos:** Sustituye TF-IDF por modelos como spaCy, fastText o sentence-transformers para captar mejor el significado de las frases.

## Respuestas m√°s naturales y emp√°ticas
Haz que ROBO suene m√°s humano:

**Variabilidad en las respuestas:** Usa listas de frases para cada tipo de respuesta y elige aleatoriamente.

**Reconocimiento de emociones:** Ya te mostr√© c√≥mo detectar emociones. Puedes usar eso para adaptar el tono de respuesta.

**Confirmaci√≥n y seguimiento:** A√±ade frases como ‚Äú¬øQuieres que te cuente m√°s sobre eso?‚Äù o ‚Äú¬øTe gustar√≠a saber algo relacionado?‚Äù

## Aprendizaje activo y retroalimentaci√≥n

Haz que el usuario pueda corregir o mejorar respuestas:

```python
def solicitar_feedback():
    return "¬øEsta respuesta fue √∫til? Puedes escribir 'mejorar' para ense√±arme una mejor."

# En send(), despu√©s de mostrar la respuesta:
chat_window.insert(tk.END, "ROBO: " + bot_reply + "\n")
chat_window.insert(tk.END, "ROBO: " + solicitar_feedback() + "\n")
```

Y si el usuario escribe ‚Äúmejorar‚Äù, puedes abrir el editor de aprendizaje directamente.

## Contexto conversacional

Actualmente ROBO responde turno por turno. Puedes mejorar esto:

**Memoria de contexto reciente:** Guarda las √∫ltimas 3‚Äì5 entradas del usuario y √∫salas para enriquecer la respuesta.

**Referencias impl√≠citas:** Si el usuario dice ‚Äú¬øy eso?‚Äù, ROBO deber√≠a saber a qu√© se refiere (usando el turno anterior).


##  Pruebas con usuarios reales

Haz que amigos o colegas interact√∫en con ROBO y te den feedback sobre:

    ¬øSe entiende lo que responde?

    ¬øEs √∫til?

    ¬øSuena natural?

    ¬øSe adapta al tono del usuario?

Puedes guardar ese feedback en una colecci√≥n evaluaciones en MongoDB para analizarlo luego.

## Integrar un modelo generativo

Si quieres dar un salto grande, puedes integrar un modelo como GPT (usando la API de OpenAI o Azure OpenAI) para generar respuestas cuando el corpus no tenga coincidencias. Lo usar√≠as como respaldo cuando TF-IDF no encuentre nada relevante.

______________________________

¬øQuieres que te ayude a implementar alguna de estas mejoras paso a paso? Podemos empezar por la que m√°s te interese: emoci√≥n, contexto, variabilidad, o incluso el modelo generativo. T√∫ decides el rumbo.

________________________________

# Sustituir TF-IDF por spaCy para similitud sem√°ntica

Usa vectores de palabras entrenados para comparar significados, no solo coincidencias de texto.

## Instalaci√≥n y carga
```bash
pip install spacy
python -m spacy download es_core_news_md
```

## Reemplazo de TF-IDF

```python
import spacy
nlp = spacy.load("es_core_news_md")

def respuesta_spacy(user_input):
    doc_input = nlp(user_input)
    similitudes = [(nlp(texto), texto, doc_input.similarity(nlp(texto))) for texto in sent_tokens]
    similitudes.sort(key=lambda x: x[2], reverse=True)
    mejor = similitudes[0]
    if mejor[2] < 0.75:
        aprendizaje.insert_one({"pregunta": user_input, "respuesta": None})
        return f"No estoy seguro, pero quiz√°s te refieres a:\n‚Üí {mejor[1]}\nLo guardar√© para aprender m√°s adelante."
    else:
        return mejor[1]
```

Y en `response()`, reemplaza el bloque TF-IDF por return `respuesta_spacy(user_response)`.

## Variabilidad en las respuestas + tono humano

Crea respuestas con m√°s personalidad:

```python
RESPUESTAS_GRACIAS = [
    "¬°De nada! üòä",
    "Siempre a tu servicio.",
    "No hay de qu√©.",
    "¬°Un placer ayudarte!"
]

RESPUESTAS_DESPEDIDA = [
    "¬°Hasta pronto!",
    "Cu√≠date mucho.",
    "Nos vemos luego.",
    "¬°Adi√≥s! Fue un gusto."
]

def respuesta_variable(tipo):
    if tipo == "gracias":
        return random.choice(RESPUESTAS_GRACIAS)
    elif tipo == "bye":
        return random.choice(RESPUESTAS_DESPEDIDA)
```

Y en send():

```python
if user_input.lower() == 'bye':
    bot_reply = respuesta_variable("bye")
elif user_input.lower() in ['gracias', 'muchas gracias']:
    bot_reply = respuesta_variable("gracias")
```

## Reconocimiento de emociones + seguimiento

```python
def detectar_emocion(texto):
    emociones = {
        "triste": ["triste", "deprimido", "mal", "llorando"],
        "feliz": ["feliz", "contento", "alegre", "genial"],
        "enojado": ["enojado", "molesto", "furioso", "rabia"]
    }
    for emocion, palabras in emociones.items():
        if any(p in texto.lower() for p in palabras):
            return emocion
    return None

def respuesta_emocional(emocion):
    frases = {
        "triste": "Siento que est√©s as√≠. ¬øQuieres que hablemos de algo que te anime?",
        "feliz": "¬°Me alegra mucho saberlo! ¬øCompartes qu√© te tiene tan contento?",
        "enojado": "Vaya, parece que algo te molest√≥. ¬øQuieres desahogarte conmigo?"
    }
    return frases.get(emocion)
```

Y en send():

```python
emocion = detectar_emocion(user_input)
if emocion:
    bot_reply = respuesta_emocional(emocion)
```

## Confirmaci√≥n y seguimiento

Despu√©s de cada respuesta, a√±ade una frase de cierre:

```python
def seguimiento():
    frases = [
        "¬øQuieres saber m√°s sobre eso?",
        "¬øTe gustar√≠a que te cuente algo relacionado?",
        "Si quieres, puedo explicarlo con m√°s detalle.",
        "¬øTe interesa otro tema parecido?"
    ]
    return random.choice(frases)
```

Y en send():

```python
chat_window.insert(tk.END, "ROBO: " + bot_reply + "\n")
chat_window.insert(tk.END, "ROBO: " + seguimiento() + "\n")
```

## Contexto conversacional + referencias impl√≠citas

Guarda los √∫ltimos turnos y responde si el usuario dice cosas como ‚Äú¬øy eso?‚Äù o ‚Äú¬øpor qu√©?‚Äù

```python

contexto_reciente = []

def actualizar_contexto(turno):
    contexto_reciente.append(turno)
    if len(contexto_reciente) > 3:
        contexto_reciente.pop(0)

def referencia_implicita(user_input):
    if user_input.lower() in ["¬øy eso?", "¬øpor qu√©?", "¬øc√≥mo as√≠?"]:
        if contexto_reciente:
            return fCreo que te refieres a esto: ‚Äú{contexto_reciente[-1]['robo']}‚Äù"
    return None
```

Y en send():

```python
referencia = referencia_implicita(user_input)
if referencia:
    bot_reply = referencia
else:
    bot_reply = response(user_input)
```

Y al final de send():

```python
turno = {"usuario": user_input, "robo": bot_reply}
actualizar_contexto(turno)
```
________________________________

¬øQuieres que te ayude a integrar todo esto directamente en tu c√≥digo actual? Puedo darte el bloque completo ya fusionado si lo prefieres. Tambi√©n podemos probarlo con ejemplos reales para afinar el comportamiento. ¬øC√≥mo te gustar√≠a seguir?

______________________________

## Sustituir TF-IDF por spaCy (sem√°ntica real)
```python
import spacy
nlp = spacy.load("es_core_news_md")

def respuesta_spacy(user_input):
    doc_input = nlp(user_input)
    similitudes = [(nlp(texto), texto, doc_input.similarity(nlp(texto))) for texto in sent_tokens]
    similitudes.sort(key=lambda x: x[2], reverse=True)
    mejor = similitudes[0]
    if mejor[2] < 0.75:
        aprendizaje.insert_one({"pregunta": user_input, "respuesta": None})
        return f"No estoy seguro, pero quiz√°s te refieres a:\n‚Üí {mejor[1]}\nLo guardar√© para aprender m√°s adelante."
    else:
        return mejor[1]
```

Y en response():

```python
def response(user_response):
    resultado = aprendizaje.find_one({"pregunta": {"$regex": user_response, "$options": "i"}})
    if resultado and resultado["respuesta"]:
        return resultado["respuesta"]

    for turno in reversed(historial_conversacion):
        if user_response.lower() in turno["usuario"].lower():
            return turno["robo"]

    respuesta_api = consulta_wikipedia(user_response)
    if respuesta_api:
        return respuesta_api

    if "clima" in user_response or "tiempo" in user_response:
        ciudad = user_response.split()[-1]
        clima = consulta_clima(ciudad)
        if clima:
            return clima

    if "fecha" in user_response or "d√≠a" in user_response:
        curiosidad = consulta_curiosidad("9/20")
        if curiosidad:
            return curiosidad

    return respuesta_spacy(user_response)
```

## Variabilidad + tono humano
```python

RESPUESTAS_GRACIAS = [
    "¬°De nada! üòä", "Siempre a tu servicio.", "No hay de qu√©.", "¬°Un placer ayudarte!"
]
RESPUESTAS_DESPEDIDA = [
    "¬°Hasta pronto!", "Cu√≠date mucho.", "Nos vemos luego.", "¬°Adi√≥s! Fue un gusto."
]

def respuesta_variable(tipo):
    if tipo == "gracias":
        return random.choice(RESPUESTAS_GRACIAS)
    elif tipo == "bye":
        return random.choice(RESPUESTAS_DESPEDIDA)
```
## Reconocimiento de emociones

```python

def detectar_emocion(texto):
    emociones = {
        "triste": ["triste", "deprimido", "mal", "llorando"],
        "feliz": ["feliz", "contento", "alegre", "genial"],
        "enojado": ["enojado", "molesto", "furioso", "rabia"]
    }
    for emocion, palabras in emociones.items():
        if any(p in texto.lower() for p in palabras):
            return emocion
    return None

def respuesta_emocional(emocion):
    frases = {
        "triste": "Siento que est√©s as√≠. ¬øQuieres que hablemos de algo que te anime?",
        "feliz": "¬°Me alegra mucho saberlo! ¬øCompartes qu√© te tiene tan contento?",
        "enojado": "Vaya, parece que algo te molest√≥. ¬øQuieres desahogarte conmigo?"
    }
    return frases.get(emocion)
```
## Confirmaci√≥n y seguimiento
```python
def seguimiento():
    frases = [
        "¬øQuieres saber m√°s sobre eso?",
        "¬øTe gustar√≠a que te cuente algo relacionado?",
        "Si quieres, puedo explicarlo con m√°s detalle.",
        "¬øTe interesa otro tema parecido?"
    ]
    return random.choice(frases)
```
## Contexto conversacional + referencias impl√≠citas
```python
contexto_reciente = []

def actualizar_contexto(turno):
    contexto_reciente.append(turno)
    if len(contexto_reciente) > 3:
        contexto_reciente.pop(0)

def referencia_implicita(user_input):
    if user_input.lower() in ["¬øy eso?", "¬øpor qu√©?", "¬øc√≥mo as√≠?"]:
        if contexto_reciente:
            return f"Creo que te refieres a esto: ‚Äú{contexto_reciente[-1]['robo']}‚Äù"
    return None
```

## Integraci√≥n en send()

Dentro de tu funci√≥n send(), a√±ade:

```python
emocion = detectar_emocion(user_input)
referencia = referencia_implicita(user_input)

if emocion:
    bot_reply = respuesta_emocional(emocion)
elif referencia:
    bot_reply = referencia
elif user_input.lower() == 'bye':
    bot_reply = respuesta_variable("bye")
elif user_input.lower() in ['gracias', 'muchas gracias']:
    bot_reply = respuesta_variable("gracias")
elif greeting(user_input) is not None:
    bot_reply = greeting(user_input)
else:
    bot_reply = response(user_input)

chat_window.insert(tk.END, "ROBO: " + bot_reply + "\n")
chat_window.insert(tk.END, "ROBO: " + seguimiento() + "\n")

turno = {"usuario": user_input, "robo": bot_reply}
memoria.insert_one(turno)
historial_conversacion.append(turno)
actualizar_contexto(turno)
```

Con esto, ROBO ser√° mucho m√°s conversacional, emp√°tico y sem√°nticamente preciso. ¬øQuieres que prepare una versi√≥n empaquetada del script completo con estas mejoras ya integradas? Tambi√©n puedo ayudarte a probarlo con ejemplos reales.